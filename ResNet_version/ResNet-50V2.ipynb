{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950e0e0d-862c-4a55-9375-dbb64136583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 291s 723ms/step - loss: 2.4845 - accuracy: 0.3004 - val_loss: 6.7397 - val_accuracy: 0.0267\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 338s 901ms/step - loss: 1.0234 - accuracy: 0.6858 - val_loss: 0.7779 - val_accuracy: 0.7613\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 125s 334ms/step - loss: 0.5576 - accuracy: 0.8248 - val_loss: 0.9360 - val_accuracy: 0.7070\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 114s 303ms/step - loss: 0.3853 - accuracy: 0.8783 - val_loss: 1.4676 - val_accuracy: 0.6053\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 114s 305ms/step - loss: 0.2790 - accuracy: 0.9139 - val_loss: 0.7269 - val_accuracy: 0.7757\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 114s 304ms/step - loss: 0.2296 - accuracy: 0.9276 - val_loss: 2.6303 - val_accuracy: 0.4790\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 114s 303ms/step - loss: 0.1852 - accuracy: 0.9418 - val_loss: 0.6098 - val_accuracy: 0.8077\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 114s 303ms/step - loss: 0.1549 - accuracy: 0.9499 - val_loss: 0.9082 - val_accuracy: 0.7467\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 114s 305ms/step - loss: 0.1337 - accuracy: 0.9577 - val_loss: 0.9880 - val_accuracy: 0.7187\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 115s 305ms/step - loss: 0.1270 - accuracy: 0.9584 - val_loss: 0.3563 - val_accuracy: 0.8843\n",
      "94/94 [==============================] - 8s 84ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         172       0.02      0.02      0.02        60\n",
      "         173       0.03      0.03      0.03        60\n",
      "         174       0.00      0.00      0.00        60\n",
      "         175       0.00      0.00      0.00        60\n",
      "         176       0.00      0.00      0.00        60\n",
      "         177       0.02      0.03      0.03        60\n",
      "         178       0.01      0.02      0.02        60\n",
      "         179       0.02      0.02      0.02        60\n",
      "         180       0.05      0.03      0.04        60\n",
      "         181       0.02      0.02      0.02        60\n",
      "         182       0.03      0.03      0.03        60\n",
      "         183       0.09      0.08      0.09        60\n",
      "         184       0.06      0.07      0.06        60\n",
      "         185       0.03      0.03      0.03        60\n",
      "         186       0.01      0.02      0.01        60\n",
      "         187       0.00      0.00      0.00        60\n",
      "         188       0.00      0.00      0.00        60\n",
      "         189       0.00      0.00      0.00        60\n",
      "         190       0.00      0.00      0.00        60\n",
      "         191       0.02      0.02      0.02        60\n",
      "         192       0.00      0.00      0.00        60\n",
      "         193       0.02      0.02      0.02        60\n",
      "         194       0.04      0.03      0.04        60\n",
      "         195       0.00      0.00      0.00        60\n",
      "         196       0.02      0.02      0.02        60\n",
      "         197       0.02      0.02      0.02        60\n",
      "         198       0.02      0.02      0.02        60\n",
      "         199       0.00      0.00      0.00        60\n",
      "         200       0.00      0.00      0.00        60\n",
      "         201       0.05      0.05      0.05        60\n",
      "         202       0.02      0.02      0.02        60\n",
      "         203       0.06      0.05      0.05        60\n",
      "         204       0.03      0.03      0.03        60\n",
      "         205       0.02      0.02      0.02        60\n",
      "         206       0.00      0.00      0.00        60\n",
      "         207       0.03      0.02      0.02        60\n",
      "         208       0.00      0.00      0.00        60\n",
      "         209       0.00      0.00      0.00        60\n",
      "         210       0.00      0.00      0.00        60\n",
      "         211       0.02      0.02      0.02        60\n",
      "         212       0.03      0.03      0.03        60\n",
      "         213       0.01      0.02      0.01        60\n",
      "         214       0.03      0.03      0.03        60\n",
      "         215       0.02      0.02      0.02        60\n",
      "         216       0.00      0.00      0.00        60\n",
      "         217       0.03      0.03      0.03        60\n",
      "         218       0.03      0.03      0.03        60\n",
      "         219       0.00      0.00      0.00        60\n",
      "         220       0.03      0.03      0.03        60\n",
      "         221       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 8s 83ms/step - loss: 0.3563 - accuracy: 0.8843\n",
      "Test accuracy: 0.8843333125114441\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-50V2)\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "x = layers.Conv2D(64, 3, strides=1, padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Residual Blocks\n",
    "def residual_block_v2(x, filters, kernel_size=3, strides=1, activation='relu'):\n",
    "    y = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation(activation)(y)\n",
    "\n",
    "    y = layers.Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "\n",
    "    shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(x)\n",
    "    shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    out = layers.add([shortcut, y])\n",
    "    out = layers.Activation(activation)(out)\n",
    "    return out\n",
    "\n",
    "# Stack of residual blocks\n",
    "x = residual_block_v2(x, filters=64)\n",
    "x = residual_block_v2(x, filters=128, strides=2)\n",
    "x = residual_block_v2(x, filters=256, strides=2)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training for 10 epochs\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=10,  # Train for 10 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred_labels, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27b38a-8b32-444b-944a-74b88c79a5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
