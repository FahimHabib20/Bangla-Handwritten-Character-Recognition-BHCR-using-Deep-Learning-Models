{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcaf81d8-9956-4906-b054-7d54b0518c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 796s 2s/step - loss: 2.0240 - accuracy: 0.4482 - val_loss: 4.7172 - val_accuracy: 0.0957\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 632s 2s/step - loss: 0.5473 - accuracy: 0.8257 - val_loss: 0.7034 - val_accuracy: 0.7710\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 665s 2s/step - loss: 0.3285 - accuracy: 0.8956 - val_loss: 0.4564 - val_accuracy: 0.8590\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 669s 2s/step - loss: 0.2137 - accuracy: 0.9316 - val_loss: 0.3499 - val_accuracy: 0.8967\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 569s 2s/step - loss: 0.1839 - accuracy: 0.9417 - val_loss: 0.4395 - val_accuracy: 0.8670\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 485s 1s/step - loss: 0.1390 - accuracy: 0.9558 - val_loss: 0.2477 - val_accuracy: 0.9237\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 419s 1s/step - loss: 0.1275 - accuracy: 0.9603 - val_loss: 0.2688 - val_accuracy: 0.9170\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 406s 1s/step - loss: 0.0993 - accuracy: 0.9698 - val_loss: 0.2683 - val_accuracy: 0.9293\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 321s 855ms/step - loss: 0.1050 - accuracy: 0.9682 - val_loss: 0.4444 - val_accuracy: 0.8967\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 284s 758ms/step - loss: 0.0890 - accuracy: 0.9723 - val_loss: 0.2905 - val_accuracy: 0.9233\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 289s 770ms/step - loss: 0.0960 - accuracy: 0.9710 - val_loss: 0.2524 - val_accuracy: 0.9313\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 287s 764ms/step - loss: 0.0763 - accuracy: 0.9773 - val_loss: 0.1796 - val_accuracy: 0.9470\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 297s 793ms/step - loss: 0.0599 - accuracy: 0.9801 - val_loss: 0.3638 - val_accuracy: 0.9103\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 288s 767ms/step - loss: 0.0867 - accuracy: 0.9739 - val_loss: 1.0312 - val_accuracy: 0.7930\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 229s 611ms/step - loss: 0.0553 - accuracy: 0.9822 - val_loss: 0.2713 - val_accuracy: 0.9337\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 166s 443ms/step - loss: 0.0620 - accuracy: 0.9821 - val_loss: 0.2380 - val_accuracy: 0.9313\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 166s 441ms/step - loss: 0.0541 - accuracy: 0.9830 - val_loss: 0.2157 - val_accuracy: 0.9463\n",
      "Epoch 17: early stopping\n",
      "94/94 [==============================] - 6s 60ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         172       0.00      0.00      0.00        60\n",
      "         173       0.04      0.05      0.05        60\n",
      "         174       0.04      0.03      0.03        60\n",
      "         175       0.02      0.02      0.02        60\n",
      "         176       0.06      0.07      0.06        60\n",
      "         177       0.02      0.02      0.02        60\n",
      "         178       0.02      0.02      0.02        60\n",
      "         179       0.03      0.03      0.03        60\n",
      "         180       0.00      0.00      0.00        60\n",
      "         181       0.03      0.03      0.03        60\n",
      "         182       0.02      0.02      0.02        60\n",
      "         183       0.03      0.03      0.03        60\n",
      "         184       0.00      0.00      0.00        60\n",
      "         185       0.02      0.02      0.02        60\n",
      "         186       0.02      0.02      0.02        60\n",
      "         187       0.02      0.02      0.02        60\n",
      "         188       0.02      0.02      0.02        60\n",
      "         189       0.02      0.02      0.02        60\n",
      "         190       0.00      0.00      0.00        60\n",
      "         191       0.00      0.00      0.00        60\n",
      "         192       0.00      0.00      0.00        60\n",
      "         193       0.03      0.03      0.03        60\n",
      "         194       0.00      0.00      0.00        60\n",
      "         195       0.00      0.00      0.00        60\n",
      "         196       0.02      0.02      0.02        60\n",
      "         197       0.02      0.02      0.02        60\n",
      "         198       0.03      0.03      0.03        60\n",
      "         199       0.02      0.02      0.02        60\n",
      "         200       0.02      0.02      0.02        60\n",
      "         201       0.02      0.02      0.02        60\n",
      "         202       0.02      0.02      0.02        60\n",
      "         203       0.04      0.05      0.05        60\n",
      "         204       0.03      0.03      0.03        60\n",
      "         205       0.02      0.02      0.02        60\n",
      "         206       0.00      0.00      0.00        60\n",
      "         207       0.03      0.03      0.03        60\n",
      "         208       0.02      0.02      0.02        60\n",
      "         209       0.00      0.00      0.00        60\n",
      "         210       0.02      0.02      0.02        60\n",
      "         211       0.02      0.02      0.02        60\n",
      "         212       0.02      0.02      0.02        60\n",
      "         213       0.02      0.02      0.02        60\n",
      "         214       0.03      0.03      0.03        60\n",
      "         215       0.02      0.02      0.02        60\n",
      "         216       0.01      0.02      0.02        60\n",
      "         217       0.03      0.03      0.03        60\n",
      "         218       0.02      0.02      0.02        60\n",
      "         219       0.02      0.02      0.02        60\n",
      "         220       0.00      0.00      0.00        60\n",
      "         221       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.2157 - accuracy: 0.9463\n",
      "Test accuracy: 0.9463333487510681\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-152V2)\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Blocks\n",
    "def residual_block_v2(x, filters, strides=1):\n",
    "    shortcut = x\n",
    "    if strides != 1 or x.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(x)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.add([shortcut, x])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Stack of residual blocks\n",
    "x = residual_block_v2(x, filters=64, strides=1)\n",
    "x = residual_block_v2(x, filters=64)\n",
    "x = residual_block_v2(x, filters=64)\n",
    "\n",
    "x = residual_block_v2(x, filters=128, strides=2)\n",
    "x = residual_block_v2(x, filters=128)\n",
    "x = residual_block_v2(x, filters=128)\n",
    "x = residual_block_v2(x, filters=128)\n",
    "\n",
    "x = residual_block_v2(x, filters=256, strides=2)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "\n",
    "x = residual_block_v2(x, filters=512, strides=2)\n",
    "x = residual_block_v2(x, filters=512)\n",
    "x = residual_block_v2(x, filters=512)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "# Training for potentially many epochs, but with early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=20,  # Train potentially for many epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "    callbacks=[early_stopping]  # Pass the early stopping callback\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred_labels, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c06f1-1f78-43e8-934a-02d1090cb782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
