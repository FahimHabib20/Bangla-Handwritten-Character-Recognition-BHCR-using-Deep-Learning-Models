{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71df1e1-5a77-4d9d-a126-f4151d3f257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 79s 200ms/step - loss: 3.4372 - accuracy: 0.1202 - val_loss: 2.9934 - val_accuracy: 0.2040\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 39s 104ms/step - loss: 2.7117 - accuracy: 0.2641 - val_loss: 2.4733 - val_accuracy: 0.3307\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 39s 105ms/step - loss: 2.3125 - accuracy: 0.3554 - val_loss: 2.1938 - val_accuracy: 0.3913\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 39s 105ms/step - loss: 2.0484 - accuracy: 0.4285 - val_loss: 1.9442 - val_accuracy: 0.4570\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 41s 109ms/step - loss: 1.8568 - accuracy: 0.4711 - val_loss: 1.8032 - val_accuracy: 0.4767\n",
      "94/94 [==============================] - 9s 83ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03        60\n",
      "           1       0.04      0.03      0.04        60\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.02      0.02      0.02        60\n",
      "           4       0.03      0.03      0.03        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.00      0.00      0.00        60\n",
      "           7       0.04      0.03      0.04        60\n",
      "           8       0.00      0.00      0.00        60\n",
      "           9       0.01      0.02      0.01        60\n",
      "          10       0.03      0.05      0.04        60\n",
      "          11       0.01      0.03      0.02        60\n",
      "          12       0.03      0.03      0.03        60\n",
      "          13       0.06      0.05      0.05        60\n",
      "          14       0.00      0.00      0.00        60\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.00      0.00      0.00        60\n",
      "          17       0.00      0.00      0.00        60\n",
      "          18       0.03      0.03      0.03        60\n",
      "          19       0.05      0.02      0.03        60\n",
      "          20       0.01      0.02      0.02        60\n",
      "          21       0.02      0.02      0.02        60\n",
      "          22       0.05      0.07      0.06        60\n",
      "          23       0.05      0.05      0.05        60\n",
      "          24       0.00      0.00      0.00        60\n",
      "          25       0.07      0.05      0.06        60\n",
      "          26       0.01      0.02      0.02        60\n",
      "          27       0.04      0.05      0.05        60\n",
      "          28       0.01      0.02      0.01        60\n",
      "          29       0.00      0.00      0.00        60\n",
      "          30       0.00      0.00      0.00        60\n",
      "          31       0.03      0.05      0.04        60\n",
      "          32       0.00      0.00      0.00        60\n",
      "          33       0.00      0.00      0.00        60\n",
      "          34       0.02      0.02      0.02        60\n",
      "          35       0.07      0.03      0.04        60\n",
      "          36       0.00      0.00      0.00        60\n",
      "          37       0.00      0.00      0.00        60\n",
      "          38       0.02      0.02      0.02        60\n",
      "          39       0.04      0.02      0.02        60\n",
      "          40       0.00      0.00      0.00        60\n",
      "          41       0.00      0.00      0.00        60\n",
      "          42       0.03      0.07      0.04        60\n",
      "          43       0.05      0.15      0.08        60\n",
      "          44       0.00      0.00      0.00        60\n",
      "          45       0.04      0.03      0.04        60\n",
      "          46       0.02      0.02      0.02        60\n",
      "          47       0.02      0.03      0.02        60\n",
      "          48       0.04      0.05      0.04        60\n",
      "          49       0.01      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.8032 - accuracy: 0.4767\n",
      "Test accuracy: 0.476666659116745\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='rgb',  # ResNet50 expects RGB images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='rgb',  # ResNet50 expects RGB images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(50, 50, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=5,  # Train for 10 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f448cf44-a0ac-40cf-9f18-8fc5ff514038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 180s 436ms/step - loss: 2.8906 - accuracy: 0.3584 - val_loss: 5.1908 - val_accuracy: 0.0603\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 164s 438ms/step - loss: 0.7997 - accuracy: 0.7888 - val_loss: 84.1602 - val_accuracy: 0.5610\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 164s 438ms/step - loss: 0.5670 - accuracy: 0.8553 - val_loss: 2.9427 - val_accuracy: 0.7907\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 164s 439ms/step - loss: 1.0953 - accuracy: 0.7319 - val_loss: 20.9669 - val_accuracy: 0.6483\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 165s 440ms/step - loss: 0.7083 - accuracy: 0.8317 - val_loss: 1.1642 - val_accuracy: 0.7260\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-50)\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "\n",
    "x = layers.ZeroPadding2D((3, 3))(inputs)\n",
    "x = layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = layers.BatchNormalization(name='bn_conv1')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(num_classes, activation='softmax', name='fc' + str(num_classes))(x)\n",
    "\n",
    "model = models.Model(inputs, x, name='resnet50')\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=5,  # Train for 5 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb133c6-3162-46b0-ac67-a451e804c8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 188s 456ms/step - loss: 2.9499 - accuracy: 0.3663 - val_loss: 5.5739 - val_accuracy: 0.0790\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 164s 437ms/step - loss: 0.9075 - accuracy: 0.7729 - val_loss: 1.6079 - val_accuracy: 0.7833\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 165s 440ms/step - loss: 0.5878 - accuracy: 0.8473 - val_loss: 0.5288 - val_accuracy: 0.8417\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 207s 552ms/step - loss: 0.5366 - accuracy: 0.8687 - val_loss: 1.1508 - val_accuracy: 0.8243\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 206s 549ms/step - loss: 0.6315 - accuracy: 0.8290 - val_loss: 1.5307 - val_accuracy: 0.8397\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 210s 560ms/step - loss: 0.4322 - accuracy: 0.8937 - val_loss: 0.7447 - val_accuracy: 0.7900\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 162s 431ms/step - loss: 0.4582 - accuracy: 0.8808 - val_loss: 0.3821 - val_accuracy: 0.8910\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 162s 432ms/step - loss: 0.5426 - accuracy: 0.8711 - val_loss: 1.5562 - val_accuracy: 0.7393\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 272s 725ms/step - loss: 0.3837 - accuracy: 0.8991 - val_loss: 0.3642 - val_accuracy: 0.9093\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 357s 952ms/step - loss: 0.2075 - accuracy: 0.9416 - val_loss: 0.3248 - val_accuracy: 0.9157\n",
      "94/94 [==============================] - 22s 199ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03        60\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.05      0.05      0.05        60\n",
      "           3       0.01      0.02      0.02        60\n",
      "           4       0.05      0.05      0.05        60\n",
      "           5       0.05      0.05      0.05        60\n",
      "           6       0.00      0.00      0.00        60\n",
      "           7       0.03      0.03      0.03        60\n",
      "           8       0.00      0.00      0.00        60\n",
      "           9       0.04      0.03      0.04        60\n",
      "          10       0.02      0.02      0.02        60\n",
      "          11       0.02      0.02      0.02        60\n",
      "          12       0.01      0.02      0.01        60\n",
      "          13       0.00      0.00      0.00        60\n",
      "          14       0.04      0.03      0.04        60\n",
      "          15       0.03      0.03      0.03        60\n",
      "          16       0.02      0.02      0.02        60\n",
      "          17       0.00      0.00      0.00        60\n",
      "          18       0.02      0.02      0.02        60\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.01      0.02      0.01        60\n",
      "          21       0.01      0.02      0.02        60\n",
      "          22       0.03      0.03      0.03        60\n",
      "          23       0.02      0.02      0.02        60\n",
      "          24       0.02      0.02      0.02        60\n",
      "          25       0.04      0.03      0.04        60\n",
      "          26       0.02      0.02      0.02        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.03      0.03      0.03        60\n",
      "          29       0.02      0.02      0.02        60\n",
      "          30       0.07      0.07      0.07        60\n",
      "          31       0.00      0.00      0.00        60\n",
      "          32       0.02      0.02      0.02        60\n",
      "          33       0.02      0.02      0.02        60\n",
      "          34       0.01      0.02      0.01        60\n",
      "          35       0.00      0.00      0.00        60\n",
      "          36       0.00      0.00      0.00        60\n",
      "          37       0.00      0.00      0.00        60\n",
      "          38       0.00      0.00      0.00        60\n",
      "          39       0.07      0.08      0.07        60\n",
      "          40       0.02      0.02      0.02        60\n",
      "          41       0.04      0.03      0.04        60\n",
      "          42       0.02      0.02      0.02        60\n",
      "          43       0.02      0.02      0.02        60\n",
      "          44       0.05      0.05      0.05        60\n",
      "          45       0.00      0.00      0.00        60\n",
      "          46       0.02      0.02      0.02        60\n",
      "          47       0.00      0.00      0.00        60\n",
      "          48       0.03      0.03      0.03        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 19s 196ms/step - loss: 0.3248 - accuracy: 0.9157\n",
      "Test accuracy: 0.9156666398048401\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-50)\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "\n",
    "x = layers.ZeroPadding2D((3, 3))(inputs)\n",
    "x = layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = layers.BatchNormalization(name='bn_conv1')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(num_classes, activation='softmax', name='fc' + str(num_classes))(x)\n",
    "\n",
    "model = models.Model(inputs, x, name='resnet50')\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=10,  # Train for 10 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb66067-d96f-4287-a6d8-4eb5259a0d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 355s 802ms/step - loss: 3.5164 - accuracy: 0.2334 - val_loss: 6.0184 - val_accuracy: 0.0760\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 404s 1s/step - loss: 1.3205 - accuracy: 0.6326 - val_loss: 0.7661 - val_accuracy: 0.7577\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 304s 810ms/step - loss: 0.7377 - accuracy: 0.7941 - val_loss: 1.5074 - val_accuracy: 0.7330\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 283s 754ms/step - loss: 0.6240 - accuracy: 0.8337 - val_loss: 1.8639 - val_accuracy: 0.8413\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 279s 745ms/step - loss: 0.4351 - accuracy: 0.8883 - val_loss: 2.0581 - val_accuracy: 0.8547\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 276s 737ms/step - loss: 0.3875 - accuracy: 0.8981 - val_loss: 0.3440 - val_accuracy: 0.9013\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 279s 744ms/step - loss: 0.3281 - accuracy: 0.9078 - val_loss: 0.3024 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 284s 758ms/step - loss: 0.2012 - accuracy: 0.9433 - val_loss: 1.1689 - val_accuracy: 0.8970\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 185s 492ms/step - loss: 0.2249 - accuracy: 0.9358 - val_loss: 0.5670 - val_accuracy: 0.8693\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 157s 418ms/step - loss: 0.2883 - accuracy: 0.9243 - val_loss: 0.2798 - val_accuracy: 0.9233\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 157s 418ms/step - loss: 0.2287 - accuracy: 0.9431 - val_loss: 0.3323 - val_accuracy: 0.9087\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 181s 482ms/step - loss: 0.1436 - accuracy: 0.9583 - val_loss: 0.3200 - val_accuracy: 0.9200\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 280s 746ms/step - loss: 0.1983 - accuracy: 0.9439 - val_loss: 0.2959 - val_accuracy: 0.9237\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 275s 733ms/step - loss: 0.2304 - accuracy: 0.9412 - val_loss: 0.4550 - val_accuracy: 0.8877\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 277s 738ms/step - loss: 0.0832 - accuracy: 0.9746 - val_loss: 0.2736 - val_accuracy: 0.9320\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 273s 729ms/step - loss: 0.0980 - accuracy: 0.9718 - val_loss: 0.2798 - val_accuracy: 0.9247\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 276s 736ms/step - loss: 0.0968 - accuracy: 0.9742 - val_loss: 0.5954 - val_accuracy: 0.8680\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 275s 733ms/step - loss: 0.1998 - accuracy: 0.9458 - val_loss: 0.8915 - val_accuracy: 0.8567\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 282s 752ms/step - loss: 0.1129 - accuracy: 0.9693 - val_loss: 0.3255 - val_accuracy: 0.9187\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 283s 754ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.3670 - val_accuracy: 0.9213\n",
      "94/94 [==============================] - 22s 198ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.02      0.02        60\n",
      "           1       0.04      0.05      0.04        60\n",
      "           2       0.02      0.02      0.02        60\n",
      "           3       0.05      0.05      0.05        60\n",
      "           4       0.01      0.02      0.02        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.00      0.00      0.00        60\n",
      "           7       0.00      0.00      0.00        60\n",
      "           8       0.00      0.00      0.00        60\n",
      "           9       0.07      0.07      0.07        60\n",
      "          10       0.04      0.05      0.05        60\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.05      0.05      0.05        60\n",
      "          13       0.03      0.03      0.03        60\n",
      "          14       0.00      0.00      0.00        60\n",
      "          15       0.04      0.05      0.05        60\n",
      "          16       0.03      0.03      0.03        60\n",
      "          17       0.07      0.07      0.07        60\n",
      "          18       0.07      0.07      0.07        60\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.03      0.03      0.03        60\n",
      "          21       0.02      0.02      0.02        60\n",
      "          22       0.00      0.00      0.00        60\n",
      "          23       0.00      0.00      0.00        60\n",
      "          24       0.03      0.03      0.03        60\n",
      "          25       0.04      0.03      0.03        60\n",
      "          26       0.00      0.00      0.00        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.03      0.03      0.03        60\n",
      "          29       0.02      0.02      0.02        60\n",
      "          30       0.02      0.02      0.02        60\n",
      "          31       0.02      0.02      0.02        60\n",
      "          32       0.00      0.00      0.00        60\n",
      "          33       0.04      0.03      0.04        60\n",
      "          34       0.02      0.02      0.02        60\n",
      "          35       0.02      0.02      0.02        60\n",
      "          36       0.00      0.00      0.00        60\n",
      "          37       0.02      0.02      0.02        60\n",
      "          38       0.00      0.00      0.00        60\n",
      "          39       0.04      0.05      0.05        60\n",
      "          40       0.04      0.03      0.04        60\n",
      "          41       0.07      0.07      0.07        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.02      0.02      0.02        60\n",
      "          44       0.02      0.02      0.02        60\n",
      "          45       0.00      0.00      0.00        60\n",
      "          46       0.02      0.02      0.02        60\n",
      "          47       0.00      0.00      0.00        60\n",
      "          48       0.02      0.02      0.02        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 19s 196ms/step - loss: 0.3670 - accuracy: 0.9213\n",
      "Test accuracy: 0.9213333129882812\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-50)\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "\n",
    "x = layers.ZeroPadding2D((3, 3))(inputs)\n",
    "x = layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = layers.BatchNormalization(name='bn_conv1')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(num_classes, activation='softmax', name='fc' + str(num_classes))(x)\n",
    "\n",
    "model = models.Model(inputs, x, name='resnet50')\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=20,  # Train for 20 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da3c690-16b2-4390-b0ce-44065014b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/16\n",
      "375/375 [==============================] - 343s 767ms/step - loss: 3.1908 - accuracy: 0.3146 - val_loss: 6.1879 - val_accuracy: 0.0527\n",
      "Epoch 2/16\n",
      "375/375 [==============================] - 288s 769ms/step - loss: 1.1424 - accuracy: 0.6995 - val_loss: 2.3621 - val_accuracy: 0.7177\n",
      "Epoch 3/16\n",
      "375/375 [==============================] - 388s 1s/step - loss: 0.6967 - accuracy: 0.8121 - val_loss: 0.7950 - val_accuracy: 0.7580\n",
      "Epoch 4/16\n",
      "375/375 [==============================] - 387s 1s/step - loss: 0.5809 - accuracy: 0.8377 - val_loss: 0.5999 - val_accuracy: 0.8340\n",
      "Epoch 5/16\n",
      "375/375 [==============================] - 388s 1s/step - loss: 0.4869 - accuracy: 0.8676 - val_loss: 0.7142 - val_accuracy: 0.8070\n",
      "Epoch 6/16\n",
      "375/375 [==============================] - 391s 1s/step - loss: 0.4188 - accuracy: 0.8852 - val_loss: 0.5527 - val_accuracy: 0.8927\n",
      "Epoch 7/16\n",
      "375/375 [==============================] - 390s 1s/step - loss: 0.6072 - accuracy: 0.8453 - val_loss: 1.5414 - val_accuracy: 0.6233\n",
      "Epoch 8/16\n",
      "375/375 [==============================] - 395s 1s/step - loss: 0.3108 - accuracy: 0.9108 - val_loss: 0.3927 - val_accuracy: 0.8953\n",
      "Epoch 9/16\n",
      "375/375 [==============================] - 389s 1s/step - loss: 0.2350 - accuracy: 0.9348 - val_loss: 4.6599 - val_accuracy: 0.7497\n",
      "Epoch 10/16\n",
      "375/375 [==============================] - 300s 799ms/step - loss: 0.2437 - accuracy: 0.9370 - val_loss: 0.4932 - val_accuracy: 0.8573\n",
      "Epoch 11/16\n",
      "375/375 [==============================] - 317s 845ms/step - loss: 0.1507 - accuracy: 0.9553 - val_loss: 0.5029 - val_accuracy: 0.8567\n",
      "Epoch 12/16\n",
      "375/375 [==============================] - 393s 1s/step - loss: 0.2453 - accuracy: 0.9365 - val_loss: 1.0096 - val_accuracy: 0.9003\n",
      "Epoch 13/16\n",
      "375/375 [==============================] - 267s 711ms/step - loss: 0.1266 - accuracy: 0.9643 - val_loss: 0.3454 - val_accuracy: 0.9040\n",
      "Epoch 14/16\n",
      "375/375 [==============================] - 178s 475ms/step - loss: 0.1910 - accuracy: 0.9448 - val_loss: 1.1209 - val_accuracy: 0.7980\n",
      "Epoch 15/16\n",
      "375/375 [==============================] - 166s 442ms/step - loss: 0.1562 - accuracy: 0.9591 - val_loss: 1.3301 - val_accuracy: 0.8817\n",
      "Epoch 16/16\n",
      "375/375 [==============================] - 164s 438ms/step - loss: 0.1009 - accuracy: 0.9712 - val_loss: 0.2726 - val_accuracy: 0.9330\n",
      "94/94 [==============================] - 8s 71ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.02      0.02        60\n",
      "           1       0.02      0.02      0.02        60\n",
      "           2       0.02      0.02      0.02        60\n",
      "           3       0.02      0.02      0.02        60\n",
      "           4       0.00      0.00      0.00        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.00      0.00      0.00        60\n",
      "           7       0.02      0.02      0.02        60\n",
      "           8       0.00      0.00      0.00        60\n",
      "           9       0.02      0.02      0.02        60\n",
      "          10       0.07      0.07      0.07        60\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.02      0.02      0.02        60\n",
      "          13       0.04      0.03      0.03        60\n",
      "          14       0.04      0.03      0.03        60\n",
      "          15       0.04      0.05      0.04        60\n",
      "          16       0.00      0.00      0.00        60\n",
      "          17       0.02      0.02      0.02        60\n",
      "          18       0.03      0.03      0.03        60\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.03      0.03      0.03        60\n",
      "          21       0.00      0.00      0.00        60\n",
      "          22       0.03      0.03      0.03        60\n",
      "          23       0.06      0.05      0.05        60\n",
      "          24       0.02      0.02      0.02        60\n",
      "          25       0.02      0.02      0.02        60\n",
      "          26       0.05      0.05      0.05        60\n",
      "          27       0.02      0.02      0.02        60\n",
      "          28       0.02      0.02      0.02        60\n",
      "          29       0.04      0.03      0.04        60\n",
      "          30       0.00      0.00      0.00        60\n",
      "          31       0.02      0.02      0.02        60\n",
      "          32       0.05      0.05      0.05        60\n",
      "          33       0.02      0.02      0.02        60\n",
      "          34       0.00      0.00      0.00        60\n",
      "          35       0.01      0.02      0.02        60\n",
      "          36       0.02      0.02      0.02        60\n",
      "          37       0.00      0.00      0.00        60\n",
      "          38       0.02      0.02      0.02        60\n",
      "          39       0.04      0.03      0.03        60\n",
      "          40       0.03      0.03      0.03        60\n",
      "          41       0.00      0.00      0.00        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.00      0.00      0.00        60\n",
      "          44       0.02      0.02      0.02        60\n",
      "          45       0.00      0.00      0.00        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.04      0.03      0.03        60\n",
      "          48       0.05      0.05      0.05        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 7s 72ms/step - loss: 0.2726 - accuracy: 0.9330\n",
      "Test accuracy: 0.9330000281333923\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-50)\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "\n",
    "x = layers.ZeroPadding2D((3, 3))(inputs)\n",
    "x = layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = layers.BatchNormalization(name='bn_conv1')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(num_classes, activation='softmax', name='fc' + str(num_classes))(x)\n",
    "\n",
    "model = models.Model(inputs, x, name='resnet50')\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=16,  # Train for 16 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7cfd41-94a4-48f1-b993-742ea51206b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/16\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 168s 401ms/step - loss: 3.5481 - accuracy: 0.2308 - val_loss: 4.6436 - val_accuracy: 0.0520\n",
      "Epoch 2/16\n",
      "375/375 [==============================] - 149s 399ms/step - loss: 2.4955 - accuracy: 0.4903 - val_loss: 73.0039 - val_accuracy: 0.0517\n",
      "Epoch 3/16\n",
      "375/375 [==============================] - 146s 390ms/step - loss: 2.8735 - accuracy: 0.4004 - val_loss: 15.2477 - val_accuracy: 0.3100\n",
      "Epoch 4/16\n",
      "375/375 [==============================] - 146s 390ms/step - loss: 1.6254 - accuracy: 0.5933 - val_loss: 1.8133 - val_accuracy: 0.6247\n",
      "Epoch 5/16\n",
      "375/375 [==============================] - 146s 390ms/step - loss: 1.4125 - accuracy: 0.6588 - val_loss: 0.9797 - val_accuracy: 0.7020\n",
      "Epoch 6/16\n",
      "375/375 [==============================] - 148s 394ms/step - loss: 1.1820 - accuracy: 0.7237 - val_loss: 2.6533 - val_accuracy: 0.4130\n",
      "Epoch 7/16\n",
      "375/375 [==============================] - 155s 413ms/step - loss: 1.1522 - accuracy: 0.7171 - val_loss: 1.3864 - val_accuracy: 0.7193\n",
      "Epoch 8/16\n",
      "375/375 [==============================] - 155s 414ms/step - loss: 0.9205 - accuracy: 0.7793 - val_loss: 1.0683 - val_accuracy: 0.7647\n",
      "Epoch 9/16\n",
      "375/375 [==============================] - 156s 417ms/step - loss: 0.5771 - accuracy: 0.8492 - val_loss: 0.8163 - val_accuracy: 0.7827\n",
      "Epoch 10/16\n",
      "375/375 [==============================] - 157s 418ms/step - loss: 0.5251 - accuracy: 0.8662 - val_loss: 0.6702 - val_accuracy: 0.8150\n",
      "Epoch 11/16\n",
      "375/375 [==============================] - 157s 419ms/step - loss: 0.7083 - accuracy: 0.8242 - val_loss: 1.9366 - val_accuracy: 0.6920\n",
      "Epoch 12/16\n",
      "375/375 [==============================] - 157s 419ms/step - loss: 0.5683 - accuracy: 0.8547 - val_loss: 0.6404 - val_accuracy: 0.8420\n",
      "Epoch 13/16\n",
      "375/375 [==============================] - 158s 422ms/step - loss: 0.4809 - accuracy: 0.8812 - val_loss: 1.7162 - val_accuracy: 0.7703\n",
      "Epoch 14/16\n",
      "375/375 [==============================] - 156s 416ms/step - loss: 0.3894 - accuracy: 0.9032 - val_loss: 0.4063 - val_accuracy: 0.8847\n",
      "Epoch 15/16\n",
      "375/375 [==============================] - 155s 413ms/step - loss: 0.5366 - accuracy: 0.8647 - val_loss: 1.5511 - val_accuracy: 0.6573\n",
      "Epoch 16/16\n",
      "375/375 [==============================] - 155s 415ms/step - loss: 0.8686 - accuracy: 0.7883 - val_loss: 0.5680 - val_accuracy: 0.8300\n",
      "94/94 [==============================] - 5s 47ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.02      0.02      0.02        60\n",
      "           2       0.04      0.03      0.04        60\n",
      "           3       0.01      0.02      0.02        60\n",
      "           4       0.01      0.02      0.02        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.03      0.03      0.03        60\n",
      "           7       0.04      0.03      0.04        60\n",
      "           8       0.10      0.08      0.09        60\n",
      "           9       0.06      0.07      0.06        60\n",
      "          10       0.00      0.00      0.00        60\n",
      "          11       0.05      0.05      0.05        60\n",
      "          12       0.00      0.00      0.00        60\n",
      "          13       0.03      0.03      0.03        60\n",
      "          14       0.00      0.00      0.00        60\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.00      0.00      0.00        60\n",
      "          17       0.02      0.02      0.02        60\n",
      "          18       0.02      0.02      0.02        60\n",
      "          19       0.02      0.02      0.02        60\n",
      "          20       0.04      0.03      0.03        60\n",
      "          21       0.00      0.00      0.00        60\n",
      "          22       0.00      0.00      0.00        60\n",
      "          23       0.04      0.05      0.05        60\n",
      "          24       0.03      0.05      0.04        60\n",
      "          25       0.03      0.03      0.03        60\n",
      "          26       0.00      0.00      0.00        60\n",
      "          27       0.03      0.03      0.03        60\n",
      "          28       0.02      0.02      0.02        60\n",
      "          29       0.03      0.03      0.03        60\n",
      "          30       0.01      0.02      0.02        60\n",
      "          31       0.04      0.02      0.02        60\n",
      "          32       0.04      0.03      0.04        60\n",
      "          33       0.04      0.05      0.04        60\n",
      "          34       0.02      0.02      0.02        60\n",
      "          35       0.00      0.00      0.00        60\n",
      "          36       0.06      0.05      0.06        60\n",
      "          37       0.04      0.03      0.03        60\n",
      "          38       0.07      0.03      0.05        60\n",
      "          39       0.01      0.02      0.02        60\n",
      "          40       0.06      0.07      0.07        60\n",
      "          41       0.09      0.08      0.09        60\n",
      "          42       0.03      0.03      0.03        60\n",
      "          43       0.07      0.07      0.07        60\n",
      "          44       0.02      0.02      0.02        60\n",
      "          45       0.03      0.05      0.04        60\n",
      "          46       0.02      0.02      0.02        60\n",
      "          47       0.02      0.02      0.02        60\n",
      "          48       0.00      0.00      0.00        60\n",
      "          49       0.06      0.05      0.05        60\n",
      "\n",
      "    accuracy                           0.03      3000\n",
      "   macro avg       0.03      0.03      0.03      3000\n",
      "weighted avg       0.03      0.03      0.03      3000\n",
      "\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.5680 - accuracy: 0.8300\n",
      "Test accuracy: 0.8299999833106995\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(28, 28),  # Resizing to 28x28 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(28, 28),  # Resizing to 28x28 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-50)\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inputs = layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.ZeroPadding2D((3, 3))(inputs)\n",
    "x = layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = layers.BatchNormalization(name='bn_conv1')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(num_classes, activation='softmax', name='fc' + str(num_classes))(x)\n",
    "\n",
    "model = models.Model(inputs, x, name='resnet50')\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=16,  # Train for 16 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663a31f-7082-4084-b966-0a6e9eb430ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
