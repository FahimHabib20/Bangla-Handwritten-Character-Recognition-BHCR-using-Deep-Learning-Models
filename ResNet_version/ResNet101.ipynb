{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fba8b9-ffa5-4796-a546-1f9d1341d6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 184s 360ms/step - loss: 1.9241 - accuracy: 0.4613 - val_loss: 3.5040 - val_accuracy: 0.2337\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 174s 465ms/step - loss: 0.5581 - accuracy: 0.8247 - val_loss: 1.8436 - val_accuracy: 0.5460\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 248s 661ms/step - loss: 0.3328 - accuracy: 0.8970 - val_loss: 0.3467 - val_accuracy: 0.8940\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 248s 659ms/step - loss: 0.2263 - accuracy: 0.9260 - val_loss: 0.2684 - val_accuracy: 0.9210\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 249s 664ms/step - loss: 0.1687 - accuracy: 0.9466 - val_loss: 0.4765 - val_accuracy: 0.8563\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 269s 719ms/step - loss: 0.1432 - accuracy: 0.9536 - val_loss: 0.4771 - val_accuracy: 0.8757\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 264s 702ms/step - loss: 0.1381 - accuracy: 0.9562 - val_loss: 1.2338 - val_accuracy: 0.7340\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 267s 713ms/step - loss: 0.1066 - accuracy: 0.9662 - val_loss: 0.2146 - val_accuracy: 0.9397\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 268s 714ms/step - loss: 0.1037 - accuracy: 0.9665 - val_loss: 0.4050 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 274s 730ms/step - loss: 0.0876 - accuracy: 0.9728 - val_loss: 0.1736 - val_accuracy: 0.9473\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 270s 717ms/step - loss: 0.0789 - accuracy: 0.9741 - val_loss: 0.1873 - val_accuracy: 0.9453\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 257s 684ms/step - loss: 0.0721 - accuracy: 0.9772 - val_loss: 0.2460 - val_accuracy: 0.9323\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 230s 611ms/step - loss: 0.0660 - accuracy: 0.9779 - val_loss: 0.1793 - val_accuracy: 0.9473\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 220s 586ms/step - loss: 0.0712 - accuracy: 0.9768 - val_loss: 0.2912 - val_accuracy: 0.9217\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 231s 615ms/step - loss: 0.0760 - accuracy: 0.9762 - val_loss: 0.2877 - val_accuracy: 0.9230\n",
      "Epoch 15: early stopping\n",
      "94/94 [==============================] - 32s 199ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         172       0.04      0.03      0.03        60\n",
      "         173       0.02      0.02      0.02        60\n",
      "         174       0.00      0.00      0.00        60\n",
      "         175       0.02      0.02      0.02        60\n",
      "         176       0.02      0.02      0.02        60\n",
      "         177       0.02      0.02      0.02        60\n",
      "         178       0.01      0.02      0.02        60\n",
      "         179       0.02      0.02      0.02        60\n",
      "         180       0.03      0.03      0.03        60\n",
      "         181       0.02      0.02      0.02        60\n",
      "         182       0.05      0.05      0.05        60\n",
      "         183       0.07      0.07      0.07        60\n",
      "         184       0.00      0.00      0.00        60\n",
      "         185       0.03      0.05      0.04        60\n",
      "         186       0.04      0.03      0.03        60\n",
      "         187       0.02      0.02      0.02        60\n",
      "         188       0.00      0.00      0.00        60\n",
      "         189       0.00      0.00      0.00        60\n",
      "         190       0.05      0.05      0.05        60\n",
      "         191       0.02      0.02      0.02        60\n",
      "         192       0.02      0.02      0.02        60\n",
      "         193       0.05      0.05      0.05        60\n",
      "         194       0.02      0.02      0.02        60\n",
      "         195       0.03      0.03      0.03        60\n",
      "         196       0.06      0.07      0.07        60\n",
      "         197       0.00      0.00      0.00        60\n",
      "         198       0.00      0.00      0.00        60\n",
      "         199       0.02      0.02      0.02        60\n",
      "         200       0.03      0.03      0.03        60\n",
      "         201       0.01      0.02      0.02        60\n",
      "         202       0.02      0.02      0.02        60\n",
      "         203       0.01      0.02      0.01        60\n",
      "         204       0.02      0.02      0.02        60\n",
      "         205       0.00      0.00      0.00        60\n",
      "         206       0.00      0.00      0.00        60\n",
      "         207       0.02      0.02      0.02        60\n",
      "         208       0.00      0.00      0.00        60\n",
      "         209       0.02      0.02      0.02        60\n",
      "         210       0.00      0.00      0.00        60\n",
      "         211       0.02      0.02      0.02        60\n",
      "         212       0.02      0.02      0.02        60\n",
      "         213       0.00      0.00      0.00        60\n",
      "         214       0.02      0.02      0.02        60\n",
      "         215       0.02      0.02      0.02        60\n",
      "         216       0.03      0.03      0.03        60\n",
      "         217       0.02      0.02      0.02        60\n",
      "         218       0.02      0.02      0.02        60\n",
      "         219       0.04      0.03      0.04        60\n",
      "         220       0.02      0.02      0.02        60\n",
      "         221       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 19s 197ms/step - loss: 0.2877 - accuracy: 0.9230\n",
      "Test accuracy: 0.9229999780654907\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-101)\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Blocks\n",
    "def residual_block(x, filters, strides=1):\n",
    "    shortcut = x\n",
    "    if strides != 1 or x.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(x)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.add([shortcut, x])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Stack of residual blocks\n",
    "x = residual_block(x, filters=64, strides=1)\n",
    "x = residual_block(x, filters=64)\n",
    "x = residual_block(x, filters=64)\n",
    "\n",
    "x = residual_block(x, filters=128, strides=2)\n",
    "x = residual_block(x, filters=128)\n",
    "x = residual_block(x, filters=128)\n",
    "x = residual_block(x, filters=128)\n",
    "\n",
    "x = residual_block(x, filters=256, strides=2)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "# Training for potentially many epochs, but with early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=20,  # Train potentially for many epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "    callbacks=[early_stopping]  # Pass the early stopping callback\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred_labels, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee4f37-8989-429d-827f-b9194e7dc15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
