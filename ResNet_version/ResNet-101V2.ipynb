{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9958f582-359b-40d4-9dd6-d347cf45fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 254s 429ms/step - loss: 1.9616 - accuracy: 0.4546 - val_loss: 4.2633 - val_accuracy: 0.1750\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 230s 614ms/step - loss: 0.5914 - accuracy: 0.8127 - val_loss: 1.1499 - val_accuracy: 0.6987\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 265s 706ms/step - loss: 0.3277 - accuracy: 0.8964 - val_loss: 0.4436 - val_accuracy: 0.8650\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 248s 662ms/step - loss: 0.2338 - accuracy: 0.9266 - val_loss: 0.4831 - val_accuracy: 0.8693\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 255s 678ms/step - loss: 0.1729 - accuracy: 0.9429 - val_loss: 0.4087 - val_accuracy: 0.8863\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 268s 714ms/step - loss: 0.1361 - accuracy: 0.9568 - val_loss: 0.2368 - val_accuracy: 0.9253\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 272s 724ms/step - loss: 0.1223 - accuracy: 0.9584 - val_loss: 0.3712 - val_accuracy: 0.8913\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 271s 721ms/step - loss: 0.1187 - accuracy: 0.9631 - val_loss: 0.3413 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 271s 721ms/step - loss: 0.0938 - accuracy: 0.9714 - val_loss: 0.9936 - val_accuracy: 0.7630\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 268s 714ms/step - loss: 0.0961 - accuracy: 0.9682 - val_loss: 0.7415 - val_accuracy: 0.8270\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 268s 713ms/step - loss: 0.0876 - accuracy: 0.9729 - val_loss: 0.2707 - val_accuracy: 0.9173\n",
      "Epoch 11: early stopping\n",
      "94/94 [==============================] - 48s 239ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         172       0.03      0.03      0.03        60\n",
      "         173       0.03      0.03      0.03        60\n",
      "         174       0.02      0.02      0.02        60\n",
      "         175       0.03      0.03      0.03        60\n",
      "         176       0.04      0.03      0.03        60\n",
      "         177       0.00      0.00      0.00        60\n",
      "         178       0.01      0.02      0.02        60\n",
      "         179       0.00      0.00      0.00        60\n",
      "         180       0.02      0.02      0.02        60\n",
      "         181       0.02      0.02      0.02        60\n",
      "         182       0.02      0.02      0.02        60\n",
      "         183       0.02      0.02      0.02        60\n",
      "         184       0.03      0.03      0.03        60\n",
      "         185       0.02      0.02      0.02        60\n",
      "         186       0.02      0.02      0.02        60\n",
      "         187       0.02      0.03      0.03        60\n",
      "         188       0.02      0.02      0.02        60\n",
      "         189       0.02      0.02      0.02        60\n",
      "         190       0.06      0.07      0.06        60\n",
      "         191       0.04      0.03      0.04        60\n",
      "         192       0.02      0.02      0.02        60\n",
      "         193       0.02      0.02      0.02        60\n",
      "         194       0.02      0.02      0.02        60\n",
      "         195       0.03      0.03      0.03        60\n",
      "         196       0.02      0.02      0.02        60\n",
      "         197       0.00      0.00      0.00        60\n",
      "         198       0.00      0.00      0.00        60\n",
      "         199       0.02      0.02      0.02        60\n",
      "         200       0.02      0.02      0.02        60\n",
      "         201       0.02      0.02      0.02        60\n",
      "         202       0.04      0.05      0.05        60\n",
      "         203       0.07      0.07      0.07        60\n",
      "         204       0.00      0.00      0.00        60\n",
      "         205       0.00      0.00      0.00        60\n",
      "         206       0.02      0.02      0.02        60\n",
      "         207       0.02      0.02      0.02        60\n",
      "         208       0.04      0.05      0.04        60\n",
      "         209       0.04      0.03      0.03        60\n",
      "         210       0.03      0.03      0.03        60\n",
      "         211       0.00      0.00      0.00        60\n",
      "         212       0.02      0.02      0.02        60\n",
      "         213       0.05      0.05      0.05        60\n",
      "         214       0.04      0.03      0.04        60\n",
      "         215       0.03      0.03      0.03        60\n",
      "         216       0.02      0.02      0.02        60\n",
      "         217       0.03      0.03      0.03        60\n",
      "         218       0.00      0.00      0.00        60\n",
      "         219       0.02      0.02      0.02        60\n",
      "         220       0.02      0.02      0.02        60\n",
      "         221       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 23s 224ms/step - loss: 0.2707 - accuracy: 0.9173\n",
      "Test accuracy: 0.9173333048820496\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-101V2)\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Blocks\n",
    "def residual_block_v2(x, filters, strides=1):\n",
    "    shortcut = x\n",
    "    if strides != 1 or x.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(x)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.add([shortcut, x])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Stack of residual blocks\n",
    "x = residual_block_v2(x, filters=64, strides=1)\n",
    "x = residual_block_v2(x, filters=64)\n",
    "x = residual_block_v2(x, filters=64)\n",
    "\n",
    "x = residual_block_v2(x, filters=128, strides=2)\n",
    "x = residual_block_v2(x, filters=128)\n",
    "x = residual_block_v2(x, filters=128)\n",
    "x = residual_block_v2(x, filters=128)\n",
    "\n",
    "x = residual_block_v2(x, filters=256, strides=2)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "x = residual_block_v2(x, filters=256)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "# Training for potentially many epochs, but with early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=100,  # Train potentially for many epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "    callbacks=[early_stopping]  # Pass the early stopping callback\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred_labels, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef87193-2738-467d-85d3-a4e5b80ccf45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
