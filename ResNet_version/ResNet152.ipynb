{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4413042-366f-4710-86b0-2b9217e035d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 1086s 2s/step - loss: 3.4205 - accuracy: 0.1446 - val_loss: 6.5941 - val_accuracy: 0.0453\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 738s 2s/step - loss: 1.1308 - accuracy: 0.6578 - val_loss: 24.9584 - val_accuracy: 0.6837\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 743s 2s/step - loss: 0.5541 - accuracy: 0.8324 - val_loss: 0.6493 - val_accuracy: 0.7983\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 664s 2s/step - loss: 0.3820 - accuracy: 0.8822 - val_loss: 168.3391 - val_accuracy: 0.3780\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 568s 2s/step - loss: 0.3843 - accuracy: 0.8792 - val_loss: 0.3945 - val_accuracy: 0.8807\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 472s 1s/step - loss: 0.2722 - accuracy: 0.9153 - val_loss: 0.4156 - val_accuracy: 0.8820\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 480s 1s/step - loss: 0.1958 - accuracy: 0.9412 - val_loss: 0.3996 - val_accuracy: 0.9087\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 361s 964ms/step - loss: 0.1613 - accuracy: 0.9475 - val_loss: 0.5134 - val_accuracy: 0.8630\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 358s 955ms/step - loss: 0.1706 - accuracy: 0.9448 - val_loss: 3.0398 - val_accuracy: 0.5877\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 351s 936ms/step - loss: 0.1099 - accuracy: 0.9660 - val_loss: 0.3562 - val_accuracy: 0.8997\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 359s 957ms/step - loss: 0.1197 - accuracy: 0.9601 - val_loss: 2.7532 - val_accuracy: 0.7057\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 359s 957ms/step - loss: 0.1006 - accuracy: 0.9668 - val_loss: 0.7296 - val_accuracy: 0.8040\n",
      "Epoch 12: early stopping\n",
      "94/94 [==============================] - 35s 300ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         172       0.01      0.02      0.01        60\n",
      "         173       0.00      0.00      0.00        60\n",
      "         174       0.02      0.02      0.02        60\n",
      "         175       0.02      0.02      0.02        60\n",
      "         176       0.00      0.00      0.00        60\n",
      "         177       0.06      0.02      0.03        60\n",
      "         178       0.06      0.03      0.04        60\n",
      "         179       0.00      0.00      0.00        60\n",
      "         180       0.02      0.03      0.03        60\n",
      "         181       0.04      0.03      0.04        60\n",
      "         182       0.04      0.03      0.04        60\n",
      "         183       0.00      0.00      0.00        60\n",
      "         184       0.07      0.07      0.07        60\n",
      "         185       0.01      0.02      0.01        60\n",
      "         186       0.05      0.05      0.05        60\n",
      "         187       0.00      0.00      0.00        60\n",
      "         188       0.01      0.02      0.02        60\n",
      "         189       0.00      0.00      0.00        60\n",
      "         190       0.02      0.02      0.02        60\n",
      "         191       0.02      0.02      0.02        60\n",
      "         192       0.02      0.02      0.02        60\n",
      "         193       0.03      0.05      0.04        60\n",
      "         194       0.06      0.05      0.05        60\n",
      "         195       0.03      0.02      0.02        60\n",
      "         196       0.05      0.07      0.05        60\n",
      "         197       0.01      0.02      0.01        60\n",
      "         198       0.01      0.02      0.01        60\n",
      "         199       0.00      0.00      0.00        60\n",
      "         200       0.02      0.02      0.02        60\n",
      "         201       0.00      0.00      0.00        60\n",
      "         202       0.00      0.00      0.00        60\n",
      "         203       0.00      0.00      0.00        60\n",
      "         204       0.03      0.02      0.02        60\n",
      "         205       0.05      0.07      0.06        60\n",
      "         206       0.00      0.00      0.00        60\n",
      "         207       0.05      0.03      0.04        60\n",
      "         208       0.04      0.08      0.05        60\n",
      "         209       0.00      0.00      0.00        60\n",
      "         210       0.00      0.00      0.00        60\n",
      "         211       0.00      0.00      0.00        60\n",
      "         212       0.10      0.07      0.08        60\n",
      "         213       0.04      0.03      0.04        60\n",
      "         214       0.01      0.02      0.02        60\n",
      "         215       0.00      0.00      0.00        60\n",
      "         216       0.01      0.02      0.01        60\n",
      "         217       0.03      0.03      0.03        60\n",
      "         218       0.06      0.08      0.07        60\n",
      "         219       0.01      0.02      0.02        60\n",
      "         220       0.02      0.02      0.02        60\n",
      "         221       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 28s 300ms/step - loss: 0.7296 - accuracy: 0.8040\n",
      "Test accuracy: 0.8040000200271606\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (ResNet-152)\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Blocks\n",
    "def residual_block(x, filters, strides=1):\n",
    "    shortcut = x\n",
    "    if strides != 1 or x.shape[-1] != filters * 4:\n",
    "        shortcut = layers.Conv2D(filters * 4, 1, strides=strides, padding='same')(x)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Conv2D(filters, 1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters * 4, 1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.add([shortcut, x])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Stack of residual blocks\n",
    "x = residual_block(x, filters=64)\n",
    "x = residual_block(x, filters=64)\n",
    "x = residual_block(x, filters=64)\n",
    "\n",
    "x = residual_block(x, filters=128, strides=2)\n",
    "x = residual_block(x, filters=128)\n",
    "x = residual_block(x, filters=128)\n",
    "x = residual_block(x, filters=128)\n",
    "\n",
    "x = residual_block(x, filters=256, strides=2)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "x = residual_block(x, filters=256)\n",
    "\n",
    "x = residual_block(x, filters=512, strides=2)\n",
    "x = residual_block(x, filters=512)\n",
    "x = residual_block(x, filters=512)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "# Training for potentially many epochs, but with early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=20,  # Train potentially for many epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "    callbacks=[early_stopping]  # Pass the early stopping callback\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred_labels, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b51029a-a69a-40ba-a6a1-8066ebeffeff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
