{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "133bb38f-8743-4e1b-aa8e-6de76f226049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\habib\\anaconda3\\lib\\site-packages (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c1772e-c400-42dd-a350-af0da5a513cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b226bdb5-9878-49f0-84d4-e90100f4c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 227s 600ms/step - loss: 1.4787 - accuracy: 0.6033 - val_loss: 0.6835 - val_accuracy: 0.8103\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 198s 528ms/step - loss: 0.3997 - accuracy: 0.8823 - val_loss: 0.5547 - val_accuracy: 0.8463\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 200s 533ms/step - loss: 0.1541 - accuracy: 0.9508 - val_loss: 0.5297 - val_accuracy: 0.8537\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 193s 514ms/step - loss: 0.0926 - accuracy: 0.9722 - val_loss: 0.5738 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 194s 516ms/step - loss: 0.0727 - accuracy: 0.9787 - val_loss: 0.7405 - val_accuracy: 0.8580\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 190s 506ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.7237 - val_accuracy: 0.8630\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 189s 503ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.6894 - val_accuracy: 0.8677\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 189s 504ms/step - loss: 0.0452 - accuracy: 0.9867 - val_loss: 0.8301 - val_accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 188s 502ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.7358 - val_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 189s 504ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.7475 - val_accuracy: 0.8610\n",
      "94/94 [==============================] - 10s 103ms/step - loss: 0.7475 - accuracy: 0.8610\n",
      "Test accuracy: 0.8610000014305115\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b44318-5528-4a7c-b796-835d8562b6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 205s 545ms/step - loss: 1.5340 - accuracy: 0.5860 - val_loss: 0.7280 - val_accuracy: 0.7913\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 202s 538ms/step - loss: 0.3805 - accuracy: 0.8871 - val_loss: 0.5613 - val_accuracy: 0.8397\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 207s 551ms/step - loss: 0.1458 - accuracy: 0.9569 - val_loss: 0.5738 - val_accuracy: 0.8623\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 196s 522ms/step - loss: 0.0801 - accuracy: 0.9743 - val_loss: 0.6916 - val_accuracy: 0.8530\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 201s 536ms/step - loss: 0.0677 - accuracy: 0.9770 - val_loss: 0.6436 - val_accuracy: 0.8497\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 196s 523ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.7139 - val_accuracy: 0.8603\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 198s 529ms/step - loss: 0.0516 - accuracy: 0.9850 - val_loss: 0.6422 - val_accuracy: 0.8693\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 213s 568ms/step - loss: 0.0367 - accuracy: 0.9894 - val_loss: 0.7445 - val_accuracy: 0.8560\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 208s 556ms/step - loss: 0.0311 - accuracy: 0.9898 - val_loss: 0.7632 - val_accuracy: 0.8590\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 196s 522ms/step - loss: 0.0406 - accuracy: 0.9871 - val_loss: 0.6462 - val_accuracy: 0.8763\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 195s 521ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.7517 - val_accuracy: 0.8760\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 194s 517ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.7175 - val_accuracy: 0.8593\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 199s 532ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.7182 - val_accuracy: 0.8583\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 196s 523ms/step - loss: 0.0289 - accuracy: 0.9919 - val_loss: 0.8269 - val_accuracy: 0.8667\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 198s 527ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.6790 - val_accuracy: 0.8713\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 194s 517ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.8621 - val_accuracy: 0.8647\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 197s 525ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.6824 - val_accuracy: 0.8787\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 189s 505ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.7920 - val_accuracy: 0.8630\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 191s 509ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.7716 - val_accuracy: 0.8783\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 190s 507ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.0457 - val_accuracy: 0.8637\n",
      "94/94 [==============================] - 10s 103ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.02      0.02      0.02        60\n",
      "           3       0.00      0.00      0.00        60\n",
      "           4       0.06      0.05      0.05        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.04      0.05      0.05        60\n",
      "           7       0.03      0.03      0.03        60\n",
      "           8       0.02      0.02      0.02        60\n",
      "           9       0.02      0.02      0.02        60\n",
      "          10       0.01      0.02      0.02        60\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.02      0.02      0.02        60\n",
      "          13       0.03      0.03      0.03        60\n",
      "          14       0.02      0.02      0.02        60\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.01      0.02      0.01        60\n",
      "          17       0.04      0.03      0.03        60\n",
      "          18       0.00      0.00      0.00        60\n",
      "          19       0.02      0.02      0.02        60\n",
      "          20       0.07      0.07      0.07        60\n",
      "          21       0.02      0.02      0.02        60\n",
      "          22       0.04      0.03      0.03        60\n",
      "          23       0.00      0.00      0.00        60\n",
      "          24       0.02      0.02      0.02        60\n",
      "          25       0.05      0.05      0.05        60\n",
      "          26       0.01      0.02      0.02        60\n",
      "          27       0.02      0.02      0.02        60\n",
      "          28       0.05      0.05      0.05        60\n",
      "          29       0.02      0.02      0.02        60\n",
      "          30       0.00      0.00      0.00        60\n",
      "          31       0.02      0.02      0.02        60\n",
      "          32       0.00      0.00      0.00        60\n",
      "          33       0.00      0.00      0.00        60\n",
      "          34       0.02      0.02      0.02        60\n",
      "          35       0.06      0.05      0.06        60\n",
      "          36       0.00      0.00      0.00        60\n",
      "          37       0.05      0.03      0.04        60\n",
      "          38       0.02      0.03      0.03        60\n",
      "          39       0.03      0.03      0.03        60\n",
      "          40       0.00      0.00      0.00        60\n",
      "          41       0.02      0.03      0.03        60\n",
      "          42       0.02      0.02      0.02        60\n",
      "          43       0.00      0.00      0.00        60\n",
      "          44       0.02      0.02      0.02        60\n",
      "          45       0.02      0.02      0.02        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.04      0.05      0.05        60\n",
      "          48       0.02      0.02      0.02        60\n",
      "          49       0.03      0.03      0.03        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 10s 101ms/step - loss: 1.0457 - accuracy: 0.8637\n",
      "Test accuracy: 0.8636666536331177\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=20,  # Train for 20 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07987234-ec70-4995-a988-f7bd094476bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 8s 19ms/step - loss: 2.7751 - accuracy: 0.2497 - val_loss: 1.3639 - val_accuracy: 0.5750\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.8739 - accuracy: 0.7309 - val_loss: 0.7483 - val_accuracy: 0.7700\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5057 - accuracy: 0.8413 - val_loss: 0.5501 - val_accuracy: 0.8253\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3377 - accuracy: 0.8914 - val_loss: 0.5556 - val_accuracy: 0.8390\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2425 - accuracy: 0.9200 - val_loss: 0.4501 - val_accuracy: 0.8673\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.05      0.04        60\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.06      0.05      0.05        60\n",
      "           3       0.01      0.02      0.01        60\n",
      "           4       0.02      0.02      0.02        60\n",
      "           5       0.02      0.02      0.02        60\n",
      "           6       0.03      0.03      0.03        60\n",
      "           7       0.03      0.03      0.03        60\n",
      "           8       0.00      0.00      0.00        60\n",
      "           9       0.00      0.00      0.00        60\n",
      "          10       0.04      0.03      0.03        60\n",
      "          11       0.03      0.03      0.03        60\n",
      "          12       0.04      0.03      0.04        60\n",
      "          13       0.02      0.02      0.02        60\n",
      "          14       0.03      0.03      0.03        60\n",
      "          15       0.03      0.03      0.03        60\n",
      "          16       0.01      0.02      0.01        60\n",
      "          17       0.01      0.02      0.02        60\n",
      "          18       0.02      0.02      0.02        60\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.02      0.02      0.02        60\n",
      "          21       0.02      0.02      0.02        60\n",
      "          22       0.00      0.00      0.00        60\n",
      "          23       0.00      0.00      0.00        60\n",
      "          24       0.06      0.07      0.06        60\n",
      "          25       0.02      0.02      0.02        60\n",
      "          26       0.02      0.02      0.02        60\n",
      "          27       0.02      0.02      0.02        60\n",
      "          28       0.00      0.00      0.00        60\n",
      "          29       0.03      0.03      0.03        60\n",
      "          30       0.05      0.05      0.05        60\n",
      "          31       0.00      0.00      0.00        60\n",
      "          32       0.00      0.00      0.00        60\n",
      "          33       0.05      0.05      0.05        60\n",
      "          34       0.02      0.02      0.02        60\n",
      "          35       0.00      0.00      0.00        60\n",
      "          36       0.00      0.00      0.00        60\n",
      "          37       0.02      0.02      0.02        60\n",
      "          38       0.03      0.03      0.03        60\n",
      "          39       0.02      0.02      0.02        60\n",
      "          40       0.02      0.02      0.02        60\n",
      "          41       0.06      0.05      0.05        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.02      0.02      0.02        60\n",
      "          44       0.00      0.00      0.00        60\n",
      "          45       0.00      0.00      0.00        60\n",
      "          46       0.04      0.03      0.04        60\n",
      "          47       0.00      0.00      0.00        60\n",
      "          48       0.02      0.02      0.02        60\n",
      "          49       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.4501 - accuracy: 0.8673\n",
      "Test accuracy: 0.8673333525657654\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=5,  # Train for 5 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2545a102-1a20-47fa-8e15-29386220dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 8s 19ms/step - loss: 2.7410 - accuracy: 0.2605 - val_loss: 1.2950 - val_accuracy: 0.6103\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.9031 - accuracy: 0.7230 - val_loss: 0.6990 - val_accuracy: 0.7847\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5278 - accuracy: 0.8337 - val_loss: 0.5305 - val_accuracy: 0.8377\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3461 - accuracy: 0.8856 - val_loss: 0.4489 - val_accuracy: 0.8703\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2530 - accuracy: 0.9170 - val_loss: 0.4784 - val_accuracy: 0.8580\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1791 - accuracy: 0.9391 - val_loss: 0.4303 - val_accuracy: 0.8713\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1383 - accuracy: 0.9538 - val_loss: 0.4383 - val_accuracy: 0.8823\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1253 - accuracy: 0.9557 - val_loss: 0.4627 - val_accuracy: 0.8817\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1037 - accuracy: 0.9643 - val_loss: 0.4059 - val_accuracy: 0.8980\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0721 - accuracy: 0.9772 - val_loss: 0.4709 - val_accuracy: 0.8873\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.02      0.02        60\n",
      "           1       0.02      0.02      0.02        60\n",
      "           2       0.01      0.02      0.02        60\n",
      "           3       0.02      0.02      0.02        60\n",
      "           4       0.04      0.03      0.04        60\n",
      "           5       0.04      0.05      0.05        60\n",
      "           6       0.00      0.00      0.00        60\n",
      "           7       0.03      0.03      0.03        60\n",
      "           8       0.02      0.02      0.02        60\n",
      "           9       0.02      0.02      0.02        60\n",
      "          10       0.03      0.03      0.03        60\n",
      "          11       0.02      0.02      0.02        60\n",
      "          12       0.02      0.02      0.02        60\n",
      "          13       0.03      0.03      0.03        60\n",
      "          14       0.02      0.02      0.02        60\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.04      0.05      0.05        60\n",
      "          17       0.00      0.00      0.00        60\n",
      "          18       0.02      0.02      0.02        60\n",
      "          19       0.02      0.02      0.02        60\n",
      "          20       0.02      0.02      0.02        60\n",
      "          21       0.00      0.00      0.00        60\n",
      "          22       0.00      0.00      0.00        60\n",
      "          23       0.02      0.02      0.02        60\n",
      "          24       0.02      0.02      0.02        60\n",
      "          25       0.04      0.03      0.03        60\n",
      "          26       0.04      0.03      0.04        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.04      0.03      0.04        60\n",
      "          29       0.02      0.02      0.02        60\n",
      "          30       0.04      0.03      0.04        60\n",
      "          31       0.02      0.02      0.02        60\n",
      "          32       0.06      0.05      0.06        60\n",
      "          33       0.02      0.02      0.02        60\n",
      "          34       0.03      0.03      0.03        60\n",
      "          35       0.01      0.02      0.01        60\n",
      "          36       0.04      0.03      0.04        60\n",
      "          37       0.03      0.03      0.03        60\n",
      "          38       0.00      0.00      0.00        60\n",
      "          39       0.03      0.03      0.03        60\n",
      "          40       0.01      0.02      0.02        60\n",
      "          41       0.00      0.00      0.00        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.04      0.03      0.03        60\n",
      "          44       0.02      0.02      0.02        60\n",
      "          45       0.00      0.00      0.00        60\n",
      "          46       0.03      0.03      0.03        60\n",
      "          47       0.04      0.03      0.04        60\n",
      "          48       0.02      0.02      0.02        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.4709 - accuracy: 0.8873\n",
      "Test accuracy: 0.887333333492279\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=10,  # Train for 10 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221dbd20-d023-4936-96ed-6f5d61d87d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 8s 19ms/step - loss: 2.6473 - accuracy: 0.2824 - val_loss: 1.2857 - val_accuracy: 0.6127\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.8787 - accuracy: 0.7247 - val_loss: 0.6737 - val_accuracy: 0.7977\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4868 - accuracy: 0.8422 - val_loss: 0.5038 - val_accuracy: 0.8440\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3224 - accuracy: 0.8924 - val_loss: 0.4853 - val_accuracy: 0.8517\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2276 - accuracy: 0.9235 - val_loss: 0.4712 - val_accuracy: 0.8547\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1709 - accuracy: 0.9428 - val_loss: 0.4381 - val_accuracy: 0.8720\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1367 - accuracy: 0.9538 - val_loss: 0.4275 - val_accuracy: 0.8827\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.1129 - accuracy: 0.9618 - val_loss: 0.4668 - val_accuracy: 0.8730\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0915 - accuracy: 0.9697 - val_loss: 0.4440 - val_accuracy: 0.8897\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0739 - accuracy: 0.9755 - val_loss: 0.4333 - val_accuracy: 0.8977\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0645 - accuracy: 0.9784 - val_loss: 0.4968 - val_accuracy: 0.8767\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.0702 - accuracy: 0.9788 - val_loss: 0.4772 - val_accuracy: 0.8933\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.0701 - accuracy: 0.9777 - val_loss: 0.4920 - val_accuracy: 0.8833\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0507 - accuracy: 0.9833 - val_loss: 0.4321 - val_accuracy: 0.8953\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0586 - accuracy: 0.9809 - val_loss: 0.5366 - val_accuracy: 0.8870\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0492 - accuracy: 0.9839 - val_loss: 0.5696 - val_accuracy: 0.8873\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0509 - accuracy: 0.9845 - val_loss: 0.4885 - val_accuracy: 0.8993\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0498 - accuracy: 0.9837 - val_loss: 0.5511 - val_accuracy: 0.8807\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 0.5688 - val_accuracy: 0.8913\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0504 - accuracy: 0.9833 - val_loss: 0.4932 - val_accuracy: 0.8930\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.03      0.03      0.03        60\n",
      "           2       0.03      0.03      0.03        60\n",
      "           3       0.02      0.02      0.02        60\n",
      "           4       0.00      0.00      0.00        60\n",
      "           5       0.05      0.05      0.05        60\n",
      "           6       0.00      0.00      0.00        60\n",
      "           7       0.02      0.02      0.02        60\n",
      "           8       0.01      0.02      0.02        60\n",
      "           9       0.05      0.05      0.05        60\n",
      "          10       0.05      0.05      0.05        60\n",
      "          11       0.03      0.03      0.03        60\n",
      "          12       0.06      0.07      0.06        60\n",
      "          13       0.00      0.00      0.00        60\n",
      "          14       0.02      0.02      0.02        60\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.00      0.00      0.00        60\n",
      "          17       0.00      0.00      0.00        60\n",
      "          18       0.02      0.02      0.02        60\n",
      "          19       0.02      0.02      0.02        60\n",
      "          20       0.02      0.02      0.02        60\n",
      "          21       0.02      0.02      0.02        60\n",
      "          22       0.02      0.02      0.02        60\n",
      "          23       0.04      0.03      0.03        60\n",
      "          24       0.05      0.05      0.05        60\n",
      "          25       0.00      0.00      0.00        60\n",
      "          26       0.00      0.00      0.00        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.00      0.00      0.00        60\n",
      "          29       0.02      0.02      0.02        60\n",
      "          30       0.00      0.00      0.00        60\n",
      "          31       0.02      0.02      0.02        60\n",
      "          32       0.06      0.05      0.05        60\n",
      "          33       0.01      0.02      0.02        60\n",
      "          34       0.03      0.03      0.03        60\n",
      "          35       0.02      0.02      0.02        60\n",
      "          36       0.02      0.02      0.02        60\n",
      "          37       0.02      0.02      0.02        60\n",
      "          38       0.02      0.02      0.02        60\n",
      "          39       0.04      0.03      0.04        60\n",
      "          40       0.02      0.02      0.02        60\n",
      "          41       0.01      0.02      0.01        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.02      0.02      0.02        60\n",
      "          44       0.03      0.03      0.03        60\n",
      "          45       0.04      0.03      0.03        60\n",
      "          46       0.02      0.02      0.02        60\n",
      "          47       0.01      0.02      0.02        60\n",
      "          48       0.00      0.00      0.00        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.4932 - accuracy: 0.8930\n",
      "Test accuracy: 0.8930000066757202\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=20,  # Train for 20 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bcc37e-0808-46c3-8062-cf146b9e3e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 8s 19ms/step - loss: 2.7210 - accuracy: 0.2708 - val_loss: 1.1444 - val_accuracy: 0.6657\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.7861 - accuracy: 0.7561 - val_loss: 0.6111 - val_accuracy: 0.8127\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4383 - accuracy: 0.8607 - val_loss: 0.5189 - val_accuracy: 0.8447\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2963 - accuracy: 0.8998 - val_loss: 0.4517 - val_accuracy: 0.8567\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2025 - accuracy: 0.9330 - val_loss: 0.4208 - val_accuracy: 0.8720\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1550 - accuracy: 0.9473 - val_loss: 0.4732 - val_accuracy: 0.8640\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1123 - accuracy: 0.9622 - val_loss: 0.4428 - val_accuracy: 0.8803\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1159 - accuracy: 0.9598 - val_loss: 0.5058 - val_accuracy: 0.8643\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0855 - accuracy: 0.9697 - val_loss: 0.4764 - val_accuracy: 0.8880\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0769 - accuracy: 0.9726 - val_loss: 0.4816 - val_accuracy: 0.8820\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0681 - accuracy: 0.9762 - val_loss: 0.5541 - val_accuracy: 0.8817\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0622 - accuracy: 0.9795 - val_loss: 0.5756 - val_accuracy: 0.8733\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.4888 - val_accuracy: 0.9023\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.5424 - val_accuracy: 0.8857\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0657 - accuracy: 0.9788 - val_loss: 0.5168 - val_accuracy: 0.8853\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0475 - accuracy: 0.9830 - val_loss: 0.5953 - val_accuracy: 0.8913\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.5453 - val_accuracy: 0.8933\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0434 - accuracy: 0.9852 - val_loss: 0.5589 - val_accuracy: 0.8920\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0507 - accuracy: 0.9845 - val_loss: 0.5377 - val_accuracy: 0.9007\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.5471 - val_accuracy: 0.9030\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.5725 - val_accuracy: 0.9017\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0412 - accuracy: 0.9868 - val_loss: 0.5365 - val_accuracy: 0.8937\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.5710 - val_accuracy: 0.8890\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0437 - accuracy: 0.9858 - val_loss: 0.6123 - val_accuracy: 0.8883\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.5888 - val_accuracy: 0.8937\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 0.5588 - val_accuracy: 0.8930\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.6405 - val_accuracy: 0.8887\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.6354 - val_accuracy: 0.8897\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 0.6380 - val_accuracy: 0.8997\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.6104 - val_accuracy: 0.9010\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0368 - accuracy: 0.9893 - val_loss: 0.7095 - val_accuracy: 0.8860\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.5923 - val_accuracy: 0.9010\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.5585 - val_accuracy: 0.8937\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 0.6053 - val_accuracy: 0.8987\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.6104 - val_accuracy: 0.9147\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.6160 - val_accuracy: 0.9013\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.6999 - val_accuracy: 0.8940\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0339 - accuracy: 0.9903 - val_loss: 0.6801 - val_accuracy: 0.9050\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.6595 - val_accuracy: 0.9020\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.6821 - val_accuracy: 0.8970\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 0.6693 - val_accuracy: 0.9013\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.6463 - val_accuracy: 0.9037\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0250 - accuracy: 0.9934 - val_loss: 0.6680 - val_accuracy: 0.8980\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.5820 - val_accuracy: 0.9130\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.6399 - val_accuracy: 0.9013\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.7203 - val_accuracy: 0.8970\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 0.6323 - val_accuracy: 0.9010\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.6177 - val_accuracy: 0.9080\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0327 - accuracy: 0.9905 - val_loss: 0.7924 - val_accuracy: 0.8967\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.6308 - val_accuracy: 0.9113\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03        60\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.02      0.02      0.02        60\n",
      "           3       0.00      0.00      0.00        60\n",
      "           4       0.05      0.05      0.05        60\n",
      "           5       0.04      0.03      0.03        60\n",
      "           6       0.03      0.03      0.03        60\n",
      "           7       0.02      0.02      0.02        60\n",
      "           8       0.02      0.02      0.02        60\n",
      "           9       0.05      0.05      0.05        60\n",
      "          10       0.00      0.00      0.00        60\n",
      "          11       0.03      0.03      0.03        60\n",
      "          12       0.00      0.00      0.00        60\n",
      "          13       0.01      0.02      0.02        60\n",
      "          14       0.00      0.00      0.00        60\n",
      "          15       0.02      0.02      0.02        60\n",
      "          16       0.00      0.00      0.00        60\n",
      "          17       0.00      0.00      0.00        60\n",
      "          18       0.02      0.02      0.02        60\n",
      "          19       0.04      0.03      0.03        60\n",
      "          20       0.05      0.05      0.05        60\n",
      "          21       0.04      0.05      0.05        60\n",
      "          22       0.03      0.03      0.03        60\n",
      "          23       0.02      0.02      0.02        60\n",
      "          24       0.00      0.00      0.00        60\n",
      "          25       0.05      0.05      0.05        60\n",
      "          26       0.04      0.05      0.05        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.03      0.03      0.03        60\n",
      "          29       0.04      0.03      0.03        60\n",
      "          30       0.00      0.00      0.00        60\n",
      "          31       0.00      0.00      0.00        60\n",
      "          32       0.02      0.02      0.02        60\n",
      "          33       0.02      0.02      0.02        60\n",
      "          34       0.00      0.00      0.00        60\n",
      "          35       0.02      0.02      0.02        60\n",
      "          36       0.06      0.05      0.06        60\n",
      "          37       0.03      0.03      0.03        60\n",
      "          38       0.04      0.03      0.03        60\n",
      "          39       0.03      0.03      0.03        60\n",
      "          40       0.04      0.03      0.04        60\n",
      "          41       0.00      0.00      0.00        60\n",
      "          42       0.02      0.02      0.02        60\n",
      "          43       0.03      0.03      0.03        60\n",
      "          44       0.00      0.00      0.00        60\n",
      "          45       0.02      0.02      0.02        60\n",
      "          46       0.02      0.02      0.02        60\n",
      "          47       0.03      0.03      0.03        60\n",
      "          48       0.00      0.00      0.00        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.6308 - accuracy: 0.9113\n",
      "Test accuracy: 0.9113333225250244\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=50,  # Train for 50 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269a70c0-1e3d-46d0-98d0-f63b0c81b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/75\n",
      "375/375 [==============================] - 8s 19ms/step - loss: 2.7405 - accuracy: 0.2626 - val_loss: 1.2027 - val_accuracy: 0.6327\n",
      "Epoch 2/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.8927 - accuracy: 0.7198 - val_loss: 0.7804 - val_accuracy: 0.7580\n",
      "Epoch 3/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4996 - accuracy: 0.8409 - val_loss: 0.5607 - val_accuracy: 0.8330\n",
      "Epoch 4/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3140 - accuracy: 0.9010 - val_loss: 0.5354 - val_accuracy: 0.8533\n",
      "Epoch 5/75\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2422 - accuracy: 0.9208 - val_loss: 0.5085 - val_accuracy: 0.8533\n",
      "Epoch 6/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1660 - accuracy: 0.9440 - val_loss: 0.5131 - val_accuracy: 0.8607\n",
      "Epoch 7/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1382 - accuracy: 0.9537 - val_loss: 0.4467 - val_accuracy: 0.8807\n",
      "Epoch 8/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1030 - accuracy: 0.9647 - val_loss: 0.4434 - val_accuracy: 0.8900\n",
      "Epoch 9/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0904 - accuracy: 0.9695 - val_loss: 0.4959 - val_accuracy: 0.8840\n",
      "Epoch 10/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0792 - accuracy: 0.9735 - val_loss: 0.4947 - val_accuracy: 0.8860\n",
      "Epoch 11/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0670 - accuracy: 0.9786 - val_loss: 0.4773 - val_accuracy: 0.8867\n",
      "Epoch 12/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0719 - accuracy: 0.9748 - val_loss: 0.5193 - val_accuracy: 0.8827\n",
      "Epoch 13/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0634 - accuracy: 0.9797 - val_loss: 0.5157 - val_accuracy: 0.8883\n",
      "Epoch 14/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.5951 - val_accuracy: 0.8720\n",
      "Epoch 15/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0523 - accuracy: 0.9822 - val_loss: 0.6194 - val_accuracy: 0.8823\n",
      "Epoch 16/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0633 - accuracy: 0.9800 - val_loss: 0.6333 - val_accuracy: 0.8710\n",
      "Epoch 17/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0603 - accuracy: 0.9818 - val_loss: 0.5374 - val_accuracy: 0.8750\n",
      "Epoch 18/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.5263 - val_accuracy: 0.9037\n",
      "Epoch 19/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0302 - accuracy: 0.9907 - val_loss: 0.5795 - val_accuracy: 0.8767\n",
      "Epoch 20/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.5785 - val_accuracy: 0.8877\n",
      "Epoch 21/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0468 - accuracy: 0.9858 - val_loss: 0.6005 - val_accuracy: 0.8883\n",
      "Epoch 22/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0364 - accuracy: 0.9873 - val_loss: 0.5758 - val_accuracy: 0.8903\n",
      "Epoch 23/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.5167 - val_accuracy: 0.9050\n",
      "Epoch 24/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.6300 - val_accuracy: 0.8940\n",
      "Epoch 25/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0512 - accuracy: 0.9845 - val_loss: 0.5712 - val_accuracy: 0.8987\n",
      "Epoch 26/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.5955 - val_accuracy: 0.8993\n",
      "Epoch 27/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.7146 - val_accuracy: 0.8847\n",
      "Epoch 28/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.5936 - val_accuracy: 0.8907\n",
      "Epoch 29/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.5692 - val_accuracy: 0.8987\n",
      "Epoch 30/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.5964 - val_accuracy: 0.9113\n",
      "Epoch 31/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0185 - accuracy: 0.9950 - val_loss: 0.7685 - val_accuracy: 0.8653\n",
      "Epoch 32/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0783 - accuracy: 0.9756 - val_loss: 0.6251 - val_accuracy: 0.8910\n",
      "Epoch 33/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.6801 - val_accuracy: 0.8957\n",
      "Epoch 34/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.6004 - val_accuracy: 0.9077\n",
      "Epoch 35/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.5987 - val_accuracy: 0.8907\n",
      "Epoch 36/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0582 - accuracy: 0.9841 - val_loss: 0.5974 - val_accuracy: 0.9000\n",
      "Epoch 37/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0430 - accuracy: 0.9870 - val_loss: 0.6157 - val_accuracy: 0.8803\n",
      "Epoch 38/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.5801 - val_accuracy: 0.9000\n",
      "Epoch 39/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.6855 - val_accuracy: 0.8960\n",
      "Epoch 40/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.7732 - val_accuracy: 0.8833\n",
      "Epoch 41/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0362 - accuracy: 0.9898 - val_loss: 0.7281 - val_accuracy: 0.8810\n",
      "Epoch 42/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.6674 - val_accuracy: 0.9043\n",
      "Epoch 43/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.7917 - val_accuracy: 0.8870\n",
      "Epoch 44/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.6688 - val_accuracy: 0.8897\n",
      "Epoch 45/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.7016 - val_accuracy: 0.8977\n",
      "Epoch 46/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.6877 - val_accuracy: 0.8893\n",
      "Epoch 47/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.7628 - val_accuracy: 0.8923\n",
      "Epoch 48/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0418 - accuracy: 0.9883 - val_loss: 0.7012 - val_accuracy: 0.8890\n",
      "Epoch 49/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.6037 - val_accuracy: 0.9080\n",
      "Epoch 50/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.6700 - val_accuracy: 0.9057\n",
      "Epoch 51/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 0.9442 - val_accuracy: 0.8750\n",
      "Epoch 52/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.6076 - val_accuracy: 0.9053\n",
      "Epoch 53/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6591 - val_accuracy: 0.9117\n",
      "Epoch 54/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.7043 - val_accuracy: 0.9030\n",
      "Epoch 55/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 0.6808 - val_accuracy: 0.8950\n",
      "Epoch 56/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.7374 - val_accuracy: 0.9013\n",
      "Epoch 57/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0270 - accuracy: 0.9919 - val_loss: 0.7413 - val_accuracy: 0.8930\n",
      "Epoch 58/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.7936 - val_accuracy: 0.8950\n",
      "Epoch 59/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.8762 - val_accuracy: 0.8843\n",
      "Epoch 60/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.7691 - val_accuracy: 0.9010\n",
      "Epoch 61/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.7335 - val_accuracy: 0.9013\n",
      "Epoch 62/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0255 - accuracy: 0.9932 - val_loss: 1.0176 - val_accuracy: 0.8673\n",
      "Epoch 63/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.7277 - val_accuracy: 0.9010\n",
      "Epoch 64/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.7188 - val_accuracy: 0.8963\n",
      "Epoch 65/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.7449 - val_accuracy: 0.9043\n",
      "Epoch 66/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.7118 - val_accuracy: 0.9107\n",
      "Epoch 67/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.3596e-04 - accuracy: 1.0000 - val_loss: 0.7218 - val_accuracy: 0.9123\n",
      "Epoch 68/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 9.8719e-05 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.9143\n",
      "Epoch 69/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.1156e-05 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.9137\n",
      "Epoch 70/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.5628e-05 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.9147\n",
      "Epoch 71/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.1748e-05 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.9150\n",
      "Epoch 72/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 9.3263e-06 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.9150\n",
      "Epoch 73/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.5775e-06 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.9157\n",
      "Epoch 74/75\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 6.2361e-06 - accuracy: 1.0000 - val_loss: 0.7527 - val_accuracy: 0.9157\n",
      "Epoch 75/75\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.1673e-06 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.9163\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.02      0.02      0.02        60\n",
      "           2       0.04      0.03      0.03        60\n",
      "           3       0.00      0.00      0.00        60\n",
      "           4       0.02      0.02      0.02        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.03      0.03      0.03        60\n",
      "           7       0.02      0.02      0.02        60\n",
      "           8       0.05      0.05      0.05        60\n",
      "           9       0.02      0.02      0.02        60\n",
      "          10       0.03      0.03      0.03        60\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.03      0.03      0.03        60\n",
      "          13       0.02      0.02      0.02        60\n",
      "          14       0.02      0.02      0.02        60\n",
      "          15       0.05      0.05      0.05        60\n",
      "          16       0.02      0.02      0.02        60\n",
      "          17       0.02      0.02      0.02        60\n",
      "          18       0.02      0.02      0.02        60\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.00      0.00      0.00        60\n",
      "          21       0.03      0.03      0.03        60\n",
      "          22       0.03      0.03      0.03        60\n",
      "          23       0.02      0.02      0.02        60\n",
      "          24       0.03      0.03      0.03        60\n",
      "          25       0.02      0.02      0.02        60\n",
      "          26       0.03      0.03      0.03        60\n",
      "          27       0.02      0.02      0.02        60\n",
      "          28       0.02      0.02      0.02        60\n",
      "          29       0.02      0.02      0.02        60\n",
      "          30       0.00      0.00      0.00        60\n",
      "          31       0.00      0.00      0.00        60\n",
      "          32       0.03      0.03      0.03        60\n",
      "          33       0.02      0.02      0.02        60\n",
      "          34       0.04      0.03      0.04        60\n",
      "          35       0.02      0.02      0.02        60\n",
      "          36       0.02      0.02      0.02        60\n",
      "          37       0.04      0.03      0.03        60\n",
      "          38       0.00      0.00      0.00        60\n",
      "          39       0.00      0.00      0.00        60\n",
      "          40       0.02      0.02      0.02        60\n",
      "          41       0.00      0.00      0.00        60\n",
      "          42       0.02      0.02      0.02        60\n",
      "          43       0.05      0.05      0.05        60\n",
      "          44       0.02      0.02      0.02        60\n",
      "          45       0.06      0.07      0.06        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.02      0.02      0.02        60\n",
      "          48       0.02      0.02      0.02        60\n",
      "          49       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.7589 - accuracy: 0.9163\n",
      "Test accuracy: 0.9163333177566528\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=75,  # Train for 75 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4f23b6-c930-4602-9918-73ddf8ce9aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 2.5344 - accuracy: 0.3083 - val_loss: 1.1841 - val_accuracy: 0.6380\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.7964 - accuracy: 0.7502 - val_loss: 0.7438 - val_accuracy: 0.7770\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4912 - accuracy: 0.8451 - val_loss: 0.5108 - val_accuracy: 0.8443\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3250 - accuracy: 0.8947 - val_loss: 0.4748 - val_accuracy: 0.8630\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2223 - accuracy: 0.9250 - val_loss: 0.4510 - val_accuracy: 0.8630\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1666 - accuracy: 0.9427 - val_loss: 0.4652 - val_accuracy: 0.8730\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1333 - accuracy: 0.9539 - val_loss: 0.5130 - val_accuracy: 0.8727\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1014 - accuracy: 0.9672 - val_loss: 0.5769 - val_accuracy: 0.8643\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0740 - accuracy: 0.9766 - val_loss: 0.5846 - val_accuracy: 0.8590\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0899 - accuracy: 0.9685 - val_loss: 0.5321 - val_accuracy: 0.8737\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0784 - accuracy: 0.9741 - val_loss: 0.5926 - val_accuracy: 0.8650\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0576 - accuracy: 0.9799 - val_loss: 0.5607 - val_accuracy: 0.8793\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0618 - accuracy: 0.9778 - val_loss: 0.5197 - val_accuracy: 0.8920\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0571 - accuracy: 0.9803 - val_loss: 0.6078 - val_accuracy: 0.8760\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0697 - accuracy: 0.9776 - val_loss: 0.5992 - val_accuracy: 0.8770\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.5739 - val_accuracy: 0.8873\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0395 - accuracy: 0.9883 - val_loss: 0.6579 - val_accuracy: 0.8697\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0602 - accuracy: 0.9819 - val_loss: 0.5514 - val_accuracy: 0.8873\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.5882 - val_accuracy: 0.8757\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0505 - accuracy: 0.9824 - val_loss: 0.6283 - val_accuracy: 0.8903\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.6300 - val_accuracy: 0.8867\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0427 - accuracy: 0.9876 - val_loss: 0.5048 - val_accuracy: 0.8977\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 0.5906 - val_accuracy: 0.8877\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0420 - accuracy: 0.9882 - val_loss: 0.5418 - val_accuracy: 0.8913\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.5911 - val_accuracy: 0.8913\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0390 - accuracy: 0.9888 - val_loss: 0.5578 - val_accuracy: 0.8867\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.5863 - val_accuracy: 0.8887\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 0.6026 - val_accuracy: 0.8967\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.6908 - val_accuracy: 0.8987\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.6788 - val_accuracy: 0.8950\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.5974 - val_accuracy: 0.9013\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.6238 - val_accuracy: 0.8957\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.6097 - val_accuracy: 0.8977\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.5258 - val_accuracy: 0.9043\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.7423 - val_accuracy: 0.8833\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0459 - accuracy: 0.9867 - val_loss: 0.6711 - val_accuracy: 0.8937\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 0.6216 - val_accuracy: 0.9023\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 0.8039 - val_accuracy: 0.8757\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.7062 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0346 - accuracy: 0.9898 - val_loss: 0.6757 - val_accuracy: 0.8903\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.7022 - val_accuracy: 0.8947\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.6706 - val_accuracy: 0.8900\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.6394 - val_accuracy: 0.8937\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 0.7720 - val_accuracy: 0.8827\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.6716 - val_accuracy: 0.8910\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.7008 - val_accuracy: 0.8887\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0259 - accuracy: 0.9930 - val_loss: 0.7610 - val_accuracy: 0.8783\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.7236 - val_accuracy: 0.9050\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0294 - accuracy: 0.9919 - val_loss: 0.6912 - val_accuracy: 0.8890\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0382 - accuracy: 0.9901 - val_loss: 0.8756 - val_accuracy: 0.8770\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.7300 - val_accuracy: 0.8987\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.7226 - val_accuracy: 0.8953\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.8230 - val_accuracy: 0.8803\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0327 - accuracy: 0.9911 - val_loss: 0.7438 - val_accuracy: 0.8893\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.8747 - val_accuracy: 0.8847\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0279 - accuracy: 0.9922 - val_loss: 0.8475 - val_accuracy: 0.8853\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.7367 - val_accuracy: 0.8937\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.8252 - val_accuracy: 0.8927\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.7306 - val_accuracy: 0.8880\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0354 - accuracy: 0.9903 - val_loss: 0.6779 - val_accuracy: 0.9010\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.7231 - val_accuracy: 0.9017\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.8492 - val_accuracy: 0.8900\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 0.7071 - val_accuracy: 0.8930\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.7695 - val_accuracy: 0.9060\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.2263e-04 - accuracy: 0.9997 - val_loss: 0.7275 - val_accuracy: 0.9080\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 9.9690e-05 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.9147\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.8383e-05 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.0416e-05 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.9167\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.5837e-05 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.2629e-05 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.9163\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.0232e-05 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.9160\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 8.3139e-06 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.9160\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 6.7970e-06 - accuracy: 1.0000 - val_loss: 0.7668 - val_accuracy: 0.9160\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 5.5770e-06 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.9163\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.5980e-06 - accuracy: 1.0000 - val_loss: 0.7775 - val_accuracy: 0.9173\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 3.7942e-06 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.9170\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.1364e-06 - accuracy: 1.0000 - val_loss: 0.7887 - val_accuracy: 0.9167\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.5901e-06 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.9160\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.1390e-06 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.9160\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.7677e-06 - accuracy: 1.0000 - val_loss: 0.8070 - val_accuracy: 0.9163\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.4611e-06 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.9167\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.2099e-06 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.9167\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.9960e-07 - accuracy: 1.0000 - val_loss: 0.8258 - val_accuracy: 0.9167\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 8.2444e-07 - accuracy: 1.0000 - val_loss: 0.8324 - val_accuracy: 0.9163\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 6.8141e-07 - accuracy: 1.0000 - val_loss: 0.8390 - val_accuracy: 0.9167\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 5.6303e-07 - accuracy: 1.0000 - val_loss: 0.8456 - val_accuracy: 0.9163\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 4.6415e-07 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.9163\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.8182e-07 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.9163\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.1413e-07 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.9163\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.5856e-07 - accuracy: 1.0000 - val_loss: 0.8729 - val_accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.1299e-07 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.9163\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.7484e-07 - accuracy: 1.0000 - val_loss: 0.8872 - val_accuracy: 0.9160\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.4386e-07 - accuracy: 1.0000 - val_loss: 0.8943 - val_accuracy: 0.9160\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.1796e-07 - accuracy: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.9160\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.6609e-08 - accuracy: 1.0000 - val_loss: 0.9093 - val_accuracy: 0.9160\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.9364e-08 - accuracy: 1.0000 - val_loss: 0.9165 - val_accuracy: 0.9160\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 6.5327e-08 - accuracy: 1.0000 - val_loss: 0.9236 - val_accuracy: 0.9163\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 5.3585e-08 - accuracy: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.9163\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 4.3690e-08 - accuracy: 1.0000 - val_loss: 0.9384 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.5932e-08 - accuracy: 1.0000 - val_loss: 0.9457 - val_accuracy: 0.9167\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.02      0.02      0.02        60\n",
      "           2       0.02      0.02      0.02        60\n",
      "           3       0.03      0.03      0.03        60\n",
      "           4       0.02      0.02      0.02        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.00      0.00      0.00        60\n",
      "           7       0.00      0.00      0.00        60\n",
      "           8       0.05      0.05      0.05        60\n",
      "           9       0.02      0.02      0.02        60\n",
      "          10       0.02      0.02      0.02        60\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.03      0.03      0.03        60\n",
      "          13       0.02      0.02      0.02        60\n",
      "          14       0.02      0.02      0.02        60\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.02      0.02      0.02        60\n",
      "          17       0.02      0.02      0.02        60\n",
      "          18       0.00      0.00      0.00        60\n",
      "          19       0.05      0.05      0.05        60\n",
      "          20       0.00      0.00      0.00        60\n",
      "          21       0.00      0.00      0.00        60\n",
      "          22       0.02      0.02      0.02        60\n",
      "          23       0.02      0.02      0.02        60\n",
      "          24       0.02      0.02      0.02        60\n",
      "          25       0.02      0.02      0.02        60\n",
      "          26       0.05      0.05      0.05        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.04      0.03      0.03        60\n",
      "          29       0.00      0.00      0.00        60\n",
      "          30       0.02      0.02      0.02        60\n",
      "          31       0.03      0.03      0.03        60\n",
      "          32       0.02      0.02      0.02        60\n",
      "          33       0.03      0.03      0.03        60\n",
      "          34       0.03      0.03      0.03        60\n",
      "          35       0.03      0.03      0.03        60\n",
      "          36       0.02      0.02      0.02        60\n",
      "          37       0.02      0.02      0.02        60\n",
      "          38       0.05      0.05      0.05        60\n",
      "          39       0.00      0.00      0.00        60\n",
      "          40       0.02      0.02      0.02        60\n",
      "          41       0.02      0.02      0.02        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.02      0.02      0.02        60\n",
      "          44       0.03      0.03      0.03        60\n",
      "          45       0.03      0.03      0.03        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.02      0.02      0.02        60\n",
      "          48       0.00      0.00      0.00        60\n",
      "          49       0.05      0.05      0.05        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.9457 - accuracy: 0.9167\n",
      "Test accuracy: 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=100,  # Train for 100 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae373c4d-8069-4cde-b34c-e84ae4685350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/200\n",
      "375/375 [==============================] - 8s 19ms/step - loss: 2.9809 - accuracy: 0.2045 - val_loss: 1.5152 - val_accuracy: 0.5337\n",
      "Epoch 2/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.9849 - accuracy: 0.6935 - val_loss: 0.7287 - val_accuracy: 0.7727\n",
      "Epoch 3/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.5237 - accuracy: 0.8336 - val_loss: 0.6062 - val_accuracy: 0.8130\n",
      "Epoch 4/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3578 - accuracy: 0.8849 - val_loss: 0.5096 - val_accuracy: 0.8560\n",
      "Epoch 5/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2510 - accuracy: 0.9175 - val_loss: 0.4634 - val_accuracy: 0.8553\n",
      "Epoch 6/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1814 - accuracy: 0.9383 - val_loss: 0.4997 - val_accuracy: 0.8643\n",
      "Epoch 7/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1368 - accuracy: 0.9542 - val_loss: 0.5097 - val_accuracy: 0.8700\n",
      "Epoch 8/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1098 - accuracy: 0.9632 - val_loss: 0.4819 - val_accuracy: 0.8757\n",
      "Epoch 9/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1038 - accuracy: 0.9652 - val_loss: 0.5339 - val_accuracy: 0.8550\n",
      "Epoch 10/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0844 - accuracy: 0.9718 - val_loss: 0.4643 - val_accuracy: 0.8807\n",
      "Epoch 11/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0832 - accuracy: 0.9725 - val_loss: 0.5144 - val_accuracy: 0.8750\n",
      "Epoch 12/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0625 - accuracy: 0.9793 - val_loss: 0.4692 - val_accuracy: 0.8950\n",
      "Epoch 13/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0682 - accuracy: 0.9777 - val_loss: 0.5236 - val_accuracy: 0.8733\n",
      "Epoch 14/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0575 - accuracy: 0.9812 - val_loss: 0.5413 - val_accuracy: 0.8763\n",
      "Epoch 15/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.5473 - val_accuracy: 0.8900\n",
      "Epoch 16/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 0.6062 - val_accuracy: 0.8713\n",
      "Epoch 17/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0640 - accuracy: 0.9791 - val_loss: 0.5444 - val_accuracy: 0.8917\n",
      "Epoch 18/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0511 - accuracy: 0.9846 - val_loss: 0.5392 - val_accuracy: 0.8923\n",
      "Epoch 19/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 0.5831 - val_accuracy: 0.8967\n",
      "Epoch 20/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.5883 - val_accuracy: 0.8943\n",
      "Epoch 21/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0584 - accuracy: 0.9813 - val_loss: 0.7154 - val_accuracy: 0.8827\n",
      "Epoch 22/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0452 - accuracy: 0.9858 - val_loss: 0.5284 - val_accuracy: 0.8953\n",
      "Epoch 23/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.5524 - val_accuracy: 0.8950\n",
      "Epoch 24/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.6758 - val_accuracy: 0.8737\n",
      "Epoch 25/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 0.5588 - val_accuracy: 0.8900\n",
      "Epoch 26/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.5933 - val_accuracy: 0.8870\n",
      "Epoch 27/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 0.6437 - val_accuracy: 0.8880\n",
      "Epoch 28/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.5991 - val_accuracy: 0.8910\n",
      "Epoch 29/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.5785 - val_accuracy: 0.8933\n",
      "Epoch 30/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 0.6139 - val_accuracy: 0.8987\n",
      "Epoch 31/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.6570 - val_accuracy: 0.8907\n",
      "Epoch 32/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0357 - accuracy: 0.9902 - val_loss: 0.6675 - val_accuracy: 0.8833\n",
      "Epoch 33/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.7011 - val_accuracy: 0.8853\n",
      "Epoch 34/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 0.5938 - val_accuracy: 0.9007\n",
      "Epoch 35/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0371 - accuracy: 0.9901 - val_loss: 0.6079 - val_accuracy: 0.8937\n",
      "Epoch 36/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.6968 - val_accuracy: 0.8997\n",
      "Epoch 37/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.6228 - val_accuracy: 0.8960\n",
      "Epoch 38/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.6395 - val_accuracy: 0.8980\n",
      "Epoch 39/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.7502 - val_accuracy: 0.8823\n",
      "Epoch 40/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0375 - accuracy: 0.9902 - val_loss: 0.5594 - val_accuracy: 0.9137\n",
      "Epoch 41/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.8294 - val_accuracy: 0.8843\n",
      "Epoch 42/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.7086 - val_accuracy: 0.8943\n",
      "Epoch 43/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.6718 - val_accuracy: 0.9013\n",
      "Epoch 44/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.6687 - val_accuracy: 0.8953\n",
      "Epoch 45/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0408 - accuracy: 0.9886 - val_loss: 0.6588 - val_accuracy: 0.8960\n",
      "Epoch 46/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.6702 - val_accuracy: 0.9073\n",
      "Epoch 47/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.6996 - val_accuracy: 0.9023\n",
      "Epoch 48/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0446 - accuracy: 0.9872 - val_loss: 0.6998 - val_accuracy: 0.8817\n",
      "Epoch 49/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.7528 - val_accuracy: 0.8830\n",
      "Epoch 50/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.6164 - val_accuracy: 0.8973\n",
      "Epoch 51/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.7467 - val_accuracy: 0.8943\n",
      "Epoch 52/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.7604 - val_accuracy: 0.8893\n",
      "Epoch 53/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.7327 - val_accuracy: 0.8913\n",
      "Epoch 54/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 0.6561 - val_accuracy: 0.9073\n",
      "Epoch 55/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.6643 - val_accuracy: 0.9110\n",
      "Epoch 56/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.7522 - val_accuracy: 0.8880\n",
      "Epoch 57/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.6716 - val_accuracy: 0.9017\n",
      "Epoch 58/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.7607 - val_accuracy: 0.9033\n",
      "Epoch 59/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.8472 - val_accuracy: 0.8830\n",
      "Epoch 60/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0386 - accuracy: 0.9908 - val_loss: 0.7645 - val_accuracy: 0.8880\n",
      "Epoch 61/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.8125 - val_accuracy: 0.8850\n",
      "Epoch 62/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.7022 - val_accuracy: 0.9027\n",
      "Epoch 63/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.6734 - val_accuracy: 0.9077\n",
      "Epoch 64/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.7167 - val_accuracy: 0.9047\n",
      "Epoch 65/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.7072 - val_accuracy: 0.9047\n",
      "Epoch 66/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.7504 - val_accuracy: 0.9053\n",
      "Epoch 67/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.8134 - val_accuracy: 0.9010\n",
      "Epoch 68/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.8716 - val_accuracy: 0.8957\n",
      "Epoch 69/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.8115 - val_accuracy: 0.8947\n",
      "Epoch 70/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.8002 - val_accuracy: 0.8887\n",
      "Epoch 71/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.8525 - val_accuracy: 0.8997\n",
      "Epoch 72/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0228 - accuracy: 0.9958 - val_loss: 0.7718 - val_accuracy: 0.9027\n",
      "Epoch 73/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.7602 - val_accuracy: 0.9000\n",
      "Epoch 74/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.8137 - val_accuracy: 0.8853\n",
      "Epoch 75/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0254 - accuracy: 0.9928 - val_loss: 0.8785 - val_accuracy: 0.8887\n",
      "Epoch 76/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 1.1161 - val_accuracy: 0.8777\n",
      "Epoch 77/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.8395 - val_accuracy: 0.9017\n",
      "Epoch 78/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.8284 - val_accuracy: 0.9033\n",
      "Epoch 79/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.8637 - val_accuracy: 0.8863\n",
      "Epoch 80/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0174 - accuracy: 0.9957 - val_loss: 0.7868 - val_accuracy: 0.9053\n",
      "Epoch 81/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0293 - accuracy: 0.9922 - val_loss: 0.9350 - val_accuracy: 0.8883\n",
      "Epoch 82/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.9092 - val_accuracy: 0.8980\n",
      "Epoch 83/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.8166 - val_accuracy: 0.9060\n",
      "Epoch 84/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0309 - accuracy: 0.9918 - val_loss: 0.9485 - val_accuracy: 0.8900\n",
      "Epoch 85/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.8528 - val_accuracy: 0.9023\n",
      "Epoch 86/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.9359 - val_accuracy: 0.8987\n",
      "Epoch 87/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.8279 - val_accuracy: 0.9117\n",
      "Epoch 88/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.7692e-04 - accuracy: 0.9998 - val_loss: 0.8439 - val_accuracy: 0.9143\n",
      "Epoch 89/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.3475e-04 - accuracy: 0.9999 - val_loss: 0.8384 - val_accuracy: 0.9153\n",
      "Epoch 90/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.0391e-05 - accuracy: 1.0000 - val_loss: 0.8353 - val_accuracy: 0.9167\n",
      "Epoch 91/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 8.8145e-06 - accuracy: 1.0000 - val_loss: 0.8389 - val_accuracy: 0.9170\n",
      "Epoch 92/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 6.8532e-06 - accuracy: 1.0000 - val_loss: 0.8424 - val_accuracy: 0.9173\n",
      "Epoch 93/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.6557e-06 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.9167\n",
      "Epoch 94/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 4.7802e-06 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.9167\n",
      "Epoch 95/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.0824e-06 - accuracy: 1.0000 - val_loss: 0.8527 - val_accuracy: 0.9167\n",
      "Epoch 96/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.5089e-06 - accuracy: 1.0000 - val_loss: 0.8565 - val_accuracy: 0.9167\n",
      "Epoch 97/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.0212e-06 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.9163\n",
      "Epoch 98/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.6051e-06 - accuracy: 1.0000 - val_loss: 0.8646 - val_accuracy: 0.9163\n",
      "Epoch 99/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.2434e-06 - accuracy: 1.0000 - val_loss: 0.8687 - val_accuracy: 0.9170\n",
      "Epoch 100/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.9292e-06 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.9170\n",
      "Epoch 101/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.6581e-06 - accuracy: 1.0000 - val_loss: 0.8778 - val_accuracy: 0.9170\n",
      "Epoch 102/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.4220e-06 - accuracy: 1.0000 - val_loss: 0.8828 - val_accuracy: 0.9173\n",
      "Epoch 103/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.2194e-06 - accuracy: 1.0000 - val_loss: 0.8879 - val_accuracy: 0.9177\n",
      "Epoch 104/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.0413e-06 - accuracy: 1.0000 - val_loss: 0.8935 - val_accuracy: 0.9177\n",
      "Epoch 105/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 8.8788e-07 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.9180\n",
      "Epoch 106/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.5532e-07 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.9177\n",
      "Epoch 107/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 6.4050e-07 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 0.9177\n",
      "Epoch 108/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.4166e-07 - accuracy: 1.0000 - val_loss: 0.9166 - val_accuracy: 0.9177\n",
      "Epoch 109/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.5676e-07 - accuracy: 1.0000 - val_loss: 0.9228 - val_accuracy: 0.9177\n",
      "Epoch 110/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.8475e-07 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.9170\n",
      "Epoch 111/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.2298e-07 - accuracy: 1.0000 - val_loss: 0.9359 - val_accuracy: 0.9173\n",
      "Epoch 112/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.7013e-07 - accuracy: 1.0000 - val_loss: 0.9427 - val_accuracy: 0.9177\n",
      "Epoch 113/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.2642e-07 - accuracy: 1.0000 - val_loss: 0.9497 - val_accuracy: 0.9173\n",
      "Epoch 114/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.8928e-07 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.9173\n",
      "Epoch 115/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.5804e-07 - accuracy: 1.0000 - val_loss: 0.9639 - val_accuracy: 0.9177\n",
      "Epoch 116/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.3208e-07 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.9177\n",
      "Epoch 117/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.0995e-07 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.9177\n",
      "Epoch 118/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 9.1513e-08 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 0.9177\n",
      "Epoch 119/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 7.6075e-08 - accuracy: 1.0000 - val_loss: 0.9925 - val_accuracy: 0.9180\n",
      "Epoch 120/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 6.2843e-08 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.9177\n",
      "Epoch 121/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.2114e-08 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.9180\n",
      "Epoch 122/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.3144e-08 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.9183\n",
      "Epoch 123/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.5743e-08 - accuracy: 1.0000 - val_loss: 1.0217 - val_accuracy: 0.9183\n",
      "Epoch 124/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.9643e-08 - accuracy: 1.0000 - val_loss: 1.0291 - val_accuracy: 0.9180\n",
      "Epoch 125/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.4329e-08 - accuracy: 1.0000 - val_loss: 1.0362 - val_accuracy: 0.9180\n",
      "Epoch 126/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.0077e-08 - accuracy: 1.0000 - val_loss: 1.0433 - val_accuracy: 0.9180\n",
      "Epoch 127/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.6908e-08 - accuracy: 1.0000 - val_loss: 1.0508 - val_accuracy: 0.9177\n",
      "Epoch 128/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.3798e-08 - accuracy: 1.0000 - val_loss: 1.0582 - val_accuracy: 0.9173\n",
      "Epoch 129/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.1235e-08 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.9173\n",
      "Epoch 130/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 9.3083e-09 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.9173\n",
      "Epoch 131/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 7.6691e-09 - accuracy: 1.0000 - val_loss: 1.0786 - val_accuracy: 0.9170\n",
      "Epoch 132/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 6.1691e-09 - accuracy: 1.0000 - val_loss: 1.0851 - val_accuracy: 0.9173\n",
      "Epoch 133/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 5.0565e-09 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.9173\n",
      "Epoch 134/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.1425e-09 - accuracy: 1.0000 - val_loss: 1.0976 - val_accuracy: 0.9180\n",
      "Epoch 135/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.4173e-09 - accuracy: 1.0000 - val_loss: 1.1037 - val_accuracy: 0.9180\n",
      "Epoch 136/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.7021e-09 - accuracy: 1.0000 - val_loss: 1.1094 - val_accuracy: 0.9183\n",
      "Epoch 137/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.1557e-09 - accuracy: 1.0000 - val_loss: 1.1149 - val_accuracy: 0.9180\n",
      "Epoch 138/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.6093e-09 - accuracy: 1.0000 - val_loss: 1.1189 - val_accuracy: 0.9180\n",
      "Epoch 139/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.2517e-09 - accuracy: 1.0000 - val_loss: 1.1233 - val_accuracy: 0.9180\n",
      "Epoch 140/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.7354e-10 - accuracy: 1.0000 - val_loss: 1.1267 - val_accuracy: 0.9180\n",
      "Epoch 141/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 1.1283 - val_accuracy: 0.9177\n",
      "Epoch 142/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 6.1591e-10 - accuracy: 1.0000 - val_loss: 1.1309 - val_accuracy: 0.9183\n",
      "Epoch 143/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.5697e-10 - accuracy: 1.0000 - val_loss: 1.1330 - val_accuracy: 0.9180\n",
      "Epoch 144/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.9736e-10 - accuracy: 1.0000 - val_loss: 1.1344 - val_accuracy: 0.9177\n",
      "Epoch 145/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.4769e-10 - accuracy: 1.0000 - val_loss: 1.1352 - val_accuracy: 0.9180\n",
      "Epoch 146/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.8809e-10 - accuracy: 1.0000 - val_loss: 1.1358 - val_accuracy: 0.9180\n",
      "Epoch 147/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.8809e-10 - accuracy: 1.0000 - val_loss: 1.1381 - val_accuracy: 0.9180\n",
      "Epoch 148/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 0.9177\n",
      "Epoch 149/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1422 - val_accuracy: 0.9180\n",
      "Epoch 150/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.9868e-10 - accuracy: 1.0000 - val_loss: 1.1438 - val_accuracy: 0.9177\n",
      "Epoch 151/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.3908e-10 - accuracy: 1.0000 - val_loss: 1.1481 - val_accuracy: 0.9180\n",
      "Epoch 152/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.2914e-10 - accuracy: 1.0000 - val_loss: 1.1498 - val_accuracy: 0.9170\n",
      "Epoch 153/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.9341e-11 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.9177\n",
      "Epoch 154/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 1.1542 - val_accuracy: 0.9177\n",
      "Epoch 155/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 1.1610 - val_accuracy: 0.9180\n",
      "Epoch 156/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 5.9605e-11 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.9177\n",
      "Epoch 157/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 1.1736 - val_accuracy: 0.9183\n",
      "Epoch 158/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 4.9671e-11 - accuracy: 1.0000 - val_loss: 1.1790 - val_accuracy: 0.9173\n",
      "Epoch 159/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.9736e-11 - accuracy: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.9173\n",
      "Epoch 160/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.9180\n",
      "Epoch 161/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 1.1938 - val_accuracy: 0.9190\n",
      "Epoch 162/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 1.1969 - val_accuracy: 0.9187\n",
      "Epoch 163/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 1.2033 - val_accuracy: 0.9180\n",
      "Epoch 164/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.9868e-11 - accuracy: 1.0000 - val_loss: 1.2106 - val_accuracy: 0.9190\n",
      "Epoch 165/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2171 - val_accuracy: 0.9177\n",
      "Epoch 166/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 1.2205 - val_accuracy: 0.9177\n",
      "Epoch 167/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 1.2276 - val_accuracy: 0.9173\n",
      "Epoch 168/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2341 - val_accuracy: 0.9173\n",
      "Epoch 169/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 1.2467 - val_accuracy: 0.9173\n",
      "Epoch 170/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2456 - val_accuracy: 0.9173\n",
      "Epoch 171/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2520 - val_accuracy: 0.9163\n",
      "Epoch 172/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2575 - val_accuracy: 0.9163\n",
      "Epoch 173/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2614 - val_accuracy: 0.9157\n",
      "Epoch 174/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2649 - val_accuracy: 0.9153\n",
      "Epoch 175/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2729 - val_accuracy: 0.9160\n",
      "Epoch 176/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2773 - val_accuracy: 0.9167\n",
      "Epoch 177/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2798 - val_accuracy: 0.9170\n",
      "Epoch 178/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2852 - val_accuracy: 0.9167\n",
      "Epoch 179/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2891 - val_accuracy: 0.9163\n",
      "Epoch 180/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2928 - val_accuracy: 0.9163\n",
      "Epoch 181/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2965 - val_accuracy: 0.9163\n",
      "Epoch 182/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.9157\n",
      "Epoch 183/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3028 - val_accuracy: 0.9167\n",
      "Epoch 184/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3072 - val_accuracy: 0.9167\n",
      "Epoch 185/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3102 - val_accuracy: 0.9167\n",
      "Epoch 186/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3129 - val_accuracy: 0.9163\n",
      "Epoch 187/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.9163\n",
      "Epoch 188/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3185 - val_accuracy: 0.9163\n",
      "Epoch 189/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3216 - val_accuracy: 0.9163\n",
      "Epoch 190/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3237 - val_accuracy: 0.9163\n",
      "Epoch 191/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3264 - val_accuracy: 0.9160\n",
      "Epoch 192/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3296 - val_accuracy: 0.9160\n",
      "Epoch 193/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3323 - val_accuracy: 0.9163\n",
      "Epoch 194/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3347 - val_accuracy: 0.9150\n",
      "Epoch 195/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3372 - val_accuracy: 0.9147\n",
      "Epoch 196/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3402 - val_accuracy: 0.9147\n",
      "Epoch 197/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3427 - val_accuracy: 0.9147\n",
      "Epoch 198/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3439 - val_accuracy: 0.9143\n",
      "Epoch 199/200\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3460 - val_accuracy: 0.9143\n",
      "Epoch 200/200\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3476 - val_accuracy: 0.9143\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03        60\n",
      "           1       0.02      0.02      0.02        60\n",
      "           2       0.03      0.03      0.03        60\n",
      "           3       0.07      0.07      0.07        60\n",
      "           4       0.00      0.00      0.00        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.02      0.02      0.02        60\n",
      "           7       0.00      0.00      0.00        60\n",
      "           8       0.00      0.00      0.00        60\n",
      "           9       0.04      0.03      0.03        60\n",
      "          10       0.04      0.03      0.03        60\n",
      "          11       0.05      0.05      0.05        60\n",
      "          12       0.04      0.03      0.03        60\n",
      "          13       0.02      0.02      0.02        60\n",
      "          14       0.04      0.05      0.05        60\n",
      "          15       0.04      0.03      0.03        60\n",
      "          16       0.03      0.03      0.03        60\n",
      "          17       0.02      0.02      0.02        60\n",
      "          18       0.00      0.00      0.00        60\n",
      "          19       0.02      0.02      0.02        60\n",
      "          20       0.02      0.02      0.02        60\n",
      "          21       0.05      0.05      0.05        60\n",
      "          22       0.05      0.05      0.05        60\n",
      "          23       0.00      0.00      0.00        60\n",
      "          24       0.02      0.02      0.02        60\n",
      "          25       0.00      0.00      0.00        60\n",
      "          26       0.00      0.00      0.00        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.00      0.00      0.00        60\n",
      "          29       0.04      0.03      0.03        60\n",
      "          30       0.03      0.03      0.03        60\n",
      "          31       0.00      0.00      0.00        60\n",
      "          32       0.00      0.00      0.00        60\n",
      "          33       0.02      0.02      0.02        60\n",
      "          34       0.00      0.00      0.00        60\n",
      "          35       0.00      0.00      0.00        60\n",
      "          36       0.03      0.03      0.03        60\n",
      "          37       0.00      0.00      0.00        60\n",
      "          38       0.00      0.00      0.00        60\n",
      "          39       0.05      0.05      0.05        60\n",
      "          40       0.04      0.03      0.04        60\n",
      "          41       0.02      0.02      0.02        60\n",
      "          42       0.05      0.05      0.05        60\n",
      "          43       0.00      0.00      0.00        60\n",
      "          44       0.03      0.03      0.03        60\n",
      "          45       0.03      0.03      0.03        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.00      0.00      0.00        60\n",
      "          48       0.00      0.00      0.00        60\n",
      "          49       0.07      0.07      0.07        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 1.3476 - accuracy: 0.9143\n",
      "Test accuracy: 0.9143333435058594\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=200,  # Train for 200 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f8ff493-ef2a-4be5-94f8-30c7512fa223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/161\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 2.4883 - accuracy: 0.3272 - val_loss: 1.1159 - val_accuracy: 0.6770\n",
      "Epoch 2/161\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.7851 - accuracy: 0.7574 - val_loss: 0.7187 - val_accuracy: 0.7793\n",
      "Epoch 3/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4584 - accuracy: 0.8520 - val_loss: 0.4898 - val_accuracy: 0.8503\n",
      "Epoch 4/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2996 - accuracy: 0.9016 - val_loss: 0.4660 - val_accuracy: 0.8580\n",
      "Epoch 5/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2046 - accuracy: 0.9327 - val_loss: 0.4337 - val_accuracy: 0.8783\n",
      "Epoch 6/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1615 - accuracy: 0.9467 - val_loss: 0.5004 - val_accuracy: 0.8617\n",
      "Epoch 7/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1221 - accuracy: 0.9588 - val_loss: 0.4409 - val_accuracy: 0.8850\n",
      "Epoch 8/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0926 - accuracy: 0.9707 - val_loss: 0.4834 - val_accuracy: 0.8803\n",
      "Epoch 9/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0832 - accuracy: 0.9702 - val_loss: 0.5010 - val_accuracy: 0.8803\n",
      "Epoch 10/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0827 - accuracy: 0.9730 - val_loss: 0.4374 - val_accuracy: 0.8857\n",
      "Epoch 11/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0749 - accuracy: 0.9768 - val_loss: 0.4766 - val_accuracy: 0.8903\n",
      "Epoch 12/161\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.0567 - accuracy: 0.9822 - val_loss: 0.5022 - val_accuracy: 0.8897\n",
      "Epoch 13/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.5121 - val_accuracy: 0.8877\n",
      "Epoch 14/161\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.0466 - accuracy: 0.9843 - val_loss: 0.4984 - val_accuracy: 0.8950\n",
      "Epoch 15/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.5536 - val_accuracy: 0.8857\n",
      "Epoch 16/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0608 - accuracy: 0.9799 - val_loss: 0.6274 - val_accuracy: 0.8750\n",
      "Epoch 17/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0600 - accuracy: 0.9801 - val_loss: 0.4857 - val_accuracy: 0.8990\n",
      "Epoch 18/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0452 - accuracy: 0.9851 - val_loss: 0.6610 - val_accuracy: 0.8803\n",
      "Epoch 19/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.5630 - val_accuracy: 0.8877\n",
      "Epoch 20/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0412 - accuracy: 0.9876 - val_loss: 0.5943 - val_accuracy: 0.8823\n",
      "Epoch 21/161\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.5297 - val_accuracy: 0.8913\n",
      "Epoch 22/161\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.5693 - val_accuracy: 0.8850\n",
      "Epoch 23/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.5791 - val_accuracy: 0.8753\n",
      "Epoch 24/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.5124 - val_accuracy: 0.9070\n",
      "Epoch 25/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0221 - accuracy: 0.9935 - val_loss: 0.5932 - val_accuracy: 0.9037\n",
      "Epoch 26/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0294 - accuracy: 0.9924 - val_loss: 0.5268 - val_accuracy: 0.8950\n",
      "Epoch 27/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0485 - accuracy: 0.9854 - val_loss: 0.5898 - val_accuracy: 0.8847\n",
      "Epoch 28/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.6479 - val_accuracy: 0.8770\n",
      "Epoch 29/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.6730 - val_accuracy: 0.8893\n",
      "Epoch 30/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.5770 - val_accuracy: 0.9063\n",
      "Epoch 31/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.5991 - val_accuracy: 0.9027\n",
      "Epoch 32/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.5694 - val_accuracy: 0.8900\n",
      "Epoch 33/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.6336 - val_accuracy: 0.8887\n",
      "Epoch 34/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 0.6751 - val_accuracy: 0.8963\n",
      "Epoch 35/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 0.6356 - val_accuracy: 0.8980\n",
      "Epoch 36/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 0.6713 - val_accuracy: 0.8793\n",
      "Epoch 37/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.5926 - val_accuracy: 0.8957\n",
      "Epoch 38/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.5689 - val_accuracy: 0.9090\n",
      "Epoch 39/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.8091 - val_accuracy: 0.8767\n",
      "Epoch 40/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.5871 - val_accuracy: 0.8963\n",
      "Epoch 41/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.7163 - val_accuracy: 0.8953\n",
      "Epoch 42/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0570 - accuracy: 0.9847 - val_loss: 0.5874 - val_accuracy: 0.9020\n",
      "Epoch 43/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.6617 - val_accuracy: 0.8950\n",
      "Epoch 44/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.7454 - val_accuracy: 0.8807\n",
      "Epoch 45/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.6311 - val_accuracy: 0.8967\n",
      "Epoch 46/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.6190 - val_accuracy: 0.8977\n",
      "Epoch 47/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.6618 - val_accuracy: 0.8957\n",
      "Epoch 48/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.6605 - val_accuracy: 0.9000\n",
      "Epoch 49/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0309 - accuracy: 0.9923 - val_loss: 0.6287 - val_accuracy: 0.9037\n",
      "Epoch 50/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.6637 - val_accuracy: 0.8897\n",
      "Epoch 51/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.7398 - val_accuracy: 0.8913\n",
      "Epoch 52/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.6182 - val_accuracy: 0.9037\n",
      "Epoch 53/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.7394 - val_accuracy: 0.8927\n",
      "Epoch 54/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.7349 - val_accuracy: 0.8957\n",
      "Epoch 55/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.5745 - val_accuracy: 0.9023\n",
      "Epoch 56/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.6298 - val_accuracy: 0.9110\n",
      "Epoch 57/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.6615e-04 - accuracy: 0.9998 - val_loss: 0.6028 - val_accuracy: 0.9103\n",
      "Epoch 58/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 6.6135e-04 - accuracy: 0.9998 - val_loss: 0.6193 - val_accuracy: 0.9033\n",
      "Epoch 59/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.8984e-04 - accuracy: 0.9999 - val_loss: 0.6484 - val_accuracy: 0.9123\n",
      "Epoch 60/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.6689e-05 - accuracy: 1.0000 - val_loss: 0.6526 - val_accuracy: 0.9117\n",
      "Epoch 61/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.8127e-05 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.9110\n",
      "Epoch 62/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.3765e-05 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.9123\n",
      "Epoch 63/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.0825e-05 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.9130\n",
      "Epoch 64/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 8.6757e-06 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.9137\n",
      "Epoch 65/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.0293e-06 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.9140\n",
      "Epoch 66/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.7413e-06 - accuracy: 1.0000 - val_loss: 0.6823 - val_accuracy: 0.9147\n",
      "Epoch 67/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 4.6997e-06 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.9147\n",
      "Epoch 68/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.8705e-06 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.9150\n",
      "Epoch 69/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.1821e-06 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.9153\n",
      "Epoch 70/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.6200e-06 - accuracy: 1.0000 - val_loss: 0.7055 - val_accuracy: 0.9160\n",
      "Epoch 71/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.1549e-06 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.9163\n",
      "Epoch 72/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.7696e-06 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.9173\n",
      "Epoch 73/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.4551e-06 - accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 0.9170\n",
      "Epoch 74/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.1961e-06 - accuracy: 1.0000 - val_loss: 0.7300 - val_accuracy: 0.9167\n",
      "Epoch 75/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 9.8258e-07 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.9163\n",
      "Epoch 76/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 8.0624e-07 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.9163\n",
      "Epoch 77/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 6.6092e-07 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.9163\n",
      "Epoch 78/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.4019e-07 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.9167\n",
      "Epoch 79/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.3678e-07 - accuracy: 1.0000 - val_loss: 0.7656 - val_accuracy: 0.9163\n",
      "Epoch 80/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.5186e-07 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.9167\n",
      "Epoch 81/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.8250e-07 - accuracy: 1.0000 - val_loss: 0.7827 - val_accuracy: 0.9167\n",
      "Epoch 82/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.2567e-07 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.9167\n",
      "Epoch 83/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.7774e-07 - accuracy: 1.0000 - val_loss: 0.8045 - val_accuracy: 0.9170\n",
      "Epoch 84/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.3767e-07 - accuracy: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.9173\n",
      "Epoch 85/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.0491e-07 - accuracy: 1.0000 - val_loss: 0.8308 - val_accuracy: 0.9173\n",
      "Epoch 86/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.9622e-08 - accuracy: 1.0000 - val_loss: 0.8428 - val_accuracy: 0.9177\n",
      "Epoch 87/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 6.0976e-08 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.9187\n",
      "Epoch 88/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 4.6541e-08 - accuracy: 1.0000 - val_loss: 0.8682 - val_accuracy: 0.9187\n",
      "Epoch 89/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.5554e-08 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.9193\n",
      "Epoch 90/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.7756e-08 - accuracy: 1.0000 - val_loss: 0.8918 - val_accuracy: 0.9193\n",
      "Epoch 91/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.1944e-08 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.9193\n",
      "Epoch 92/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.7722e-08 - accuracy: 1.0000 - val_loss: 0.9122 - val_accuracy: 0.9193\n",
      "Epoch 93/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.4166e-08 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.9187\n",
      "Epoch 94/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.1454e-08 - accuracy: 1.0000 - val_loss: 0.9303 - val_accuracy: 0.9187\n",
      "Epoch 95/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.3480e-09 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.9190\n",
      "Epoch 96/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.6989e-09 - accuracy: 1.0000 - val_loss: 0.9464 - val_accuracy: 0.9197\n",
      "Epoch 97/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 6.3181e-09 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.9197\n",
      "Epoch 98/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.2353e-09 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.9190\n",
      "Epoch 99/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.3412e-09 - accuracy: 1.0000 - val_loss: 0.9678 - val_accuracy: 0.9187\n",
      "Epoch 100/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.5067e-09 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9183\n",
      "Epoch 101/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.9306e-09 - accuracy: 1.0000 - val_loss: 0.9809 - val_accuracy: 0.9187\n",
      "Epoch 102/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.4140e-09 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 0.9187\n",
      "Epoch 103/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.9868e-09 - accuracy: 1.0000 - val_loss: 0.9927 - val_accuracy: 0.9183\n",
      "Epoch 104/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.5994e-09 - accuracy: 1.0000 - val_loss: 0.9985 - val_accuracy: 0.9180\n",
      "Epoch 105/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.2616e-09 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 0.9183\n",
      "Epoch 106/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.0331e-09 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.9183\n",
      "Epoch 107/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 8.0466e-10 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.9173\n",
      "Epoch 108/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.9170\n",
      "Epoch 109/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.3644e-10 - accuracy: 1.0000 - val_loss: 1.0259 - val_accuracy: 0.9163\n",
      "Epoch 110/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.1723e-10 - accuracy: 1.0000 - val_loss: 1.0320 - val_accuracy: 0.9157\n",
      "Epoch 111/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 1.0394 - val_accuracy: 0.9157\n",
      "Epoch 112/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.3776e-10 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.9153\n",
      "Epoch 113/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 1.0560 - val_accuracy: 0.9150\n",
      "Epoch 114/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 1.0635 - val_accuracy: 0.9153\n",
      "Epoch 115/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.0862e-10 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.9153\n",
      "Epoch 116/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.9868e-10 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.9150\n",
      "Epoch 117/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.8875e-10 - accuracy: 1.0000 - val_loss: 1.0957 - val_accuracy: 0.9143\n",
      "Epoch 118/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.3908e-10 - accuracy: 1.0000 - val_loss: 1.1079 - val_accuracy: 0.9143\n",
      "Epoch 119/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1231 - val_accuracy: 0.9143\n",
      "Epoch 120/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 1.1351 - val_accuracy: 0.9143\n",
      "Epoch 121/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 8.9407e-11 - accuracy: 1.0000 - val_loss: 1.1528 - val_accuracy: 0.9127\n",
      "Epoch 122/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 6.9539e-11 - accuracy: 1.0000 - val_loss: 1.1743 - val_accuracy: 0.9133\n",
      "Epoch 123/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 1.1914 - val_accuracy: 0.9137\n",
      "Epoch 124/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.9605e-11 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.9137\n",
      "Epoch 125/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 4.9671e-11 - accuracy: 1.0000 - val_loss: 1.2386 - val_accuracy: 0.9133\n",
      "Epoch 126/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.9605e-11 - accuracy: 1.0000 - val_loss: 1.2530 - val_accuracy: 0.9137\n",
      "Epoch 127/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.9736e-11 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.9120\n",
      "Epoch 128/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 6.9539e-11 - accuracy: 1.0000 - val_loss: 1.3105 - val_accuracy: 0.9123\n",
      "Epoch 129/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 1.3314 - val_accuracy: 0.9127\n",
      "Epoch 130/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.9736e-11 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.9107\n",
      "Epoch 131/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.9868e-11 - accuracy: 1.0000 - val_loss: 1.3890 - val_accuracy: 0.9097\n",
      "Epoch 132/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.9736e-11 - accuracy: 1.0000 - val_loss: 1.4162 - val_accuracy: 0.9090\n",
      "Epoch 133/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 1.4307 - val_accuracy: 0.9087\n",
      "Epoch 134/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 1.4588 - val_accuracy: 0.9083\n",
      "Epoch 135/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 1.4870 - val_accuracy: 0.9087\n",
      "Epoch 136/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.9736e-11 - accuracy: 1.0000 - val_loss: 1.5021 - val_accuracy: 0.9087\n",
      "Epoch 137/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 1.5306 - val_accuracy: 0.9083\n",
      "Epoch 138/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 9.9341e-12 - accuracy: 1.0000 - val_loss: 1.5637 - val_accuracy: 0.9087\n",
      "Epoch 139/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.9868e-11 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.9077\n",
      "Epoch 140/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 1.6270 - val_accuracy: 0.9083\n",
      "Epoch 141/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 1.6506 - val_accuracy: 0.9077\n",
      "Epoch 142/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6923 - val_accuracy: 0.9077\n",
      "Epoch 143/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.9083\n",
      "Epoch 144/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1275 - accuracy: 0.9808 - val_loss: 0.8216 - val_accuracy: 0.8533\n",
      "Epoch 145/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0602 - accuracy: 0.9825 - val_loss: 0.5349 - val_accuracy: 0.9097\n",
      "Epoch 146/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6109 - val_accuracy: 0.9100\n",
      "Epoch 147/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.5848 - val_accuracy: 0.9163\n",
      "Epoch 148/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.4357e-04 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.9167\n",
      "Epoch 149/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.5796e-05 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.9167\n",
      "Epoch 150/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 3.0874e-05 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.9167\n",
      "Epoch 151/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.3915e-05 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.9163\n",
      "Epoch 152/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.9111e-05 - accuracy: 1.0000 - val_loss: 0.6168 - val_accuracy: 0.9163\n",
      "Epoch 153/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.5487e-05 - accuracy: 1.0000 - val_loss: 0.6230 - val_accuracy: 0.9173\n",
      "Epoch 154/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.2660e-05 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 0.9177\n",
      "Epoch 155/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.0416e-05 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.9180\n",
      "Epoch 156/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 8.6025e-06 - accuracy: 1.0000 - val_loss: 0.6412 - val_accuracy: 0.9180\n",
      "Epoch 157/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 7.1062e-06 - accuracy: 1.0000 - val_loss: 0.6474 - val_accuracy: 0.9180\n",
      "Epoch 158/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 5.8827e-06 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.9180\n",
      "Epoch 159/161\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 4.8762e-06 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.9180\n",
      "Epoch 160/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 4.0314e-06 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.9187\n",
      "Epoch 161/161\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 3.3373e-06 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.9187\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03        60\n",
      "           1       0.02      0.02      0.02        60\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.01      0.02      0.02        60\n",
      "           4       0.02      0.02      0.02        60\n",
      "           5       0.02      0.02      0.02        60\n",
      "           6       0.00      0.00      0.00        60\n",
      "           7       0.00      0.00      0.00        60\n",
      "           8       0.03      0.03      0.03        60\n",
      "           9       0.00      0.00      0.00        60\n",
      "          10       0.05      0.05      0.05        60\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.00      0.00      0.00        60\n",
      "          13       0.02      0.02      0.02        60\n",
      "          14       0.03      0.03      0.03        60\n",
      "          15       0.03      0.03      0.03        60\n",
      "          16       0.00      0.00      0.00        60\n",
      "          17       0.00      0.00      0.00        60\n",
      "          18       0.03      0.03      0.03        60\n",
      "          19       0.02      0.02      0.02        60\n",
      "          20       0.00      0.00      0.00        60\n",
      "          21       0.02      0.02      0.02        60\n",
      "          22       0.03      0.03      0.03        60\n",
      "          23       0.02      0.02      0.02        60\n",
      "          24       0.00      0.00      0.00        60\n",
      "          25       0.04      0.03      0.03        60\n",
      "          26       0.02      0.02      0.02        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.03      0.03      0.03        60\n",
      "          29       0.05      0.05      0.05        60\n",
      "          30       0.03      0.03      0.03        60\n",
      "          31       0.01      0.02      0.02        60\n",
      "          32       0.03      0.03      0.03        60\n",
      "          33       0.02      0.02      0.02        60\n",
      "          34       0.02      0.02      0.02        60\n",
      "          35       0.02      0.02      0.02        60\n",
      "          36       0.02      0.02      0.02        60\n",
      "          37       0.02      0.02      0.02        60\n",
      "          38       0.02      0.02      0.02        60\n",
      "          39       0.04      0.03      0.03        60\n",
      "          40       0.00      0.00      0.00        60\n",
      "          41       0.04      0.03      0.03        60\n",
      "          42       0.05      0.05      0.05        60\n",
      "          43       0.00      0.00      0.00        60\n",
      "          44       0.02      0.02      0.02        60\n",
      "          45       0.02      0.02      0.02        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.05      0.05      0.05        60\n",
      "          48       0.00      0.00      0.00        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.6724 - accuracy: 0.9187\n",
      "Test accuracy: 0.918666660785675\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=161,  # Train for 161 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513ea911-ea22-45c7-9e93-e94a825adfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 246s 647ms/step - loss: 4.6925 - accuracy: 0.3887 - val_loss: 3.5568 - val_accuracy: 0.1713\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.7345 - accuracy: 0.7833 - val_loss: 0.7362 - val_accuracy: 0.7737\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 236s 628ms/step - loss: 0.3878 - accuracy: 0.8796 - val_loss: 0.5571 - val_accuracy: 0.8420\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.2228 - accuracy: 0.9277 - val_loss: 0.6145 - val_accuracy: 0.8383\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.1640 - accuracy: 0.9467 - val_loss: 0.5671 - val_accuracy: 0.8493\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 220s 587ms/step - loss: 0.1091 - accuracy: 0.9638 - val_loss: 0.4627 - val_accuracy: 0.8783\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 220s 587ms/step - loss: 0.0829 - accuracy: 0.9722 - val_loss: 0.5961 - val_accuracy: 0.8540\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0809 - accuracy: 0.9728 - val_loss: 0.4907 - val_accuracy: 0.8820\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 221s 588ms/step - loss: 0.0844 - accuracy: 0.9717 - val_loss: 0.6270 - val_accuracy: 0.8530\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0620 - accuracy: 0.9798 - val_loss: 0.4956 - val_accuracy: 0.8807\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0558 - accuracy: 0.9810 - val_loss: 0.5092 - val_accuracy: 0.8797\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0453 - accuracy: 0.9861 - val_loss: 0.6036 - val_accuracy: 0.8743\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0622 - accuracy: 0.9804 - val_loss: 0.5626 - val_accuracy: 0.8797\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 220s 587ms/step - loss: 0.0631 - accuracy: 0.9797 - val_loss: 0.6352 - val_accuracy: 0.8663\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.4582 - val_accuracy: 0.8997\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.5161 - val_accuracy: 0.8940\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.6547 - val_accuracy: 0.8810\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0554 - accuracy: 0.9816 - val_loss: 0.7223 - val_accuracy: 0.8597\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.5720 - val_accuracy: 0.8837\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.5792 - val_accuracy: 0.8887\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 221s 588ms/step - loss: 0.0306 - accuracy: 0.9910 - val_loss: 0.5575 - val_accuracy: 0.8970\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.4677 - val_accuracy: 0.9073\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.5737 - val_accuracy: 0.8967\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.5876 - val_accuracy: 0.8973\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.6087 - val_accuracy: 0.8960\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 0.5472 - val_accuracy: 0.9027\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.6652 - val_accuracy: 0.8880\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 221s 588ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.5951 - val_accuracy: 0.8890\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.7760 - val_accuracy: 0.8783\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.5995 - val_accuracy: 0.8900\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 221s 588ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.5934 - val_accuracy: 0.8913\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 220s 588ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.5755 - val_accuracy: 0.8987\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.5954 - val_accuracy: 0.9017\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.6378 - val_accuracy: 0.8930\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.6284 - val_accuracy: 0.8933\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.5772 - val_accuracy: 0.9040\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5559 - val_accuracy: 0.9057\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.5554 - val_accuracy: 0.9090\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.7699 - val_accuracy: 0.8863\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 221s 588ms/step - loss: 0.0478 - accuracy: 0.9868 - val_loss: 0.6101 - val_accuracy: 0.9017\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.5071 - val_accuracy: 0.9110\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.5052 - val_accuracy: 0.9123\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 6.7714e-04 - accuracy: 0.9999 - val_loss: 0.4645 - val_accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 8.1096e-05 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.9210\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 3.6245e-05 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9203\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 2.4294e-05 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9207\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 1.5938e-05 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.9207\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 1.2347e-05 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9210\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 223s 594ms/step - loss: 9.6667e-06 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.9217\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 8.1508e-06 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 6.1961e-06 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.9227\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 5.3295e-06 - accuracy: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.9227\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 4.1176e-06 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.9227\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 3.8442e-06 - accuracy: 1.0000 - val_loss: 0.5164 - val_accuracy: 0.9240\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 221s 588ms/step - loss: 2.6838e-06 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.9243\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 2.3556e-06 - accuracy: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.9240\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 1.9537e-06 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.9247\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 1.5741e-06 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.9250\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 1.2511e-06 - accuracy: 1.0000 - val_loss: 0.5385 - val_accuracy: 0.9247\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 1.0152e-06 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.9247\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 221s 589ms/step - loss: 8.4467e-07 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.9247\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 221s 591ms/step - loss: 6.8040e-07 - accuracy: 1.0000 - val_loss: 0.5511 - val_accuracy: 0.9250\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 221s 591ms/step - loss: 5.3150e-07 - accuracy: 1.0000 - val_loss: 0.5569 - val_accuracy: 0.9253\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 4.7843e-07 - accuracy: 1.0000 - val_loss: 0.5599 - val_accuracy: 0.9253\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 3.7041e-07 - accuracy: 1.0000 - val_loss: 0.5657 - val_accuracy: 0.9257\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 3.2182e-07 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.9257\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 2.5929e-07 - accuracy: 1.0000 - val_loss: 0.5746 - val_accuracy: 0.9260\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 1.9826e-07 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.9260\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 1.7896e-07 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.9257\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 1.3603e-07 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.9260\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 1.1769e-07 - accuracy: 1.0000 - val_loss: 0.5944 - val_accuracy: 0.9263\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 9.7950e-08 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.9263\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 7.9572e-08 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.9267\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 6.6618e-08 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.9263\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 4.9581e-08 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.9270\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 4.4952e-08 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.9263\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 221s 590ms/step - loss: 3.7352e-08 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.9257\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 3.1938e-08 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.9263\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 2.5372e-08 - accuracy: 1.0000 - val_loss: 0.6319 - val_accuracy: 0.9263\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 2.3663e-08 - accuracy: 1.0000 - val_loss: 0.6381 - val_accuracy: 0.9263\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 1.9511e-08 - accuracy: 1.0000 - val_loss: 0.6425 - val_accuracy: 0.9263\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 1.5815e-08 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 0.9263\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 1.3073e-08 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.9267\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 1.0957e-08 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.9263\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 1.1424e-08 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.9273\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 8.7519e-09 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.9267\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 6.3578e-09 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.9267\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 7.4108e-09 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.9280\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 6.0399e-09 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.9277\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 4.7982e-09 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.9277\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 9.7850e-09 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.9283\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 3.7551e-09 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.9277\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.9273\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 221s 591ms/step - loss: 2.9604e-09 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.9287\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 3.1491e-09 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.9273\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 222s 591ms/step - loss: 2.7716e-09 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.9290\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 2.1259e-09 - accuracy: 1.0000 - val_loss: 0.6621 - val_accuracy: 0.9280\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 2.7617e-09 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.9287\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 2.6325e-09 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.9273\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 222s 592ms/step - loss: 1.8577e-09 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.9273\n",
      "94/94 [==============================] - 14s 143ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.02      0.02        60\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.02      0.02      0.02        60\n",
      "           3       0.05      0.05      0.05        60\n",
      "           4       0.02      0.02      0.02        60\n",
      "           5       0.02      0.02      0.02        60\n",
      "           6       0.05      0.05      0.05        60\n",
      "           7       0.05      0.05      0.05        60\n",
      "           8       0.02      0.02      0.02        60\n",
      "           9       0.00      0.00      0.00        60\n",
      "          10       0.03      0.03      0.03        60\n",
      "          11       0.03      0.03      0.03        60\n",
      "          12       0.04      0.05      0.05        60\n",
      "          13       0.00      0.00      0.00        60\n",
      "          14       0.02      0.02      0.02        60\n",
      "          15       0.02      0.02      0.02        60\n",
      "          16       0.02      0.02      0.02        60\n",
      "          17       0.02      0.02      0.02        60\n",
      "          18       0.00      0.00      0.00        60\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.03      0.03      0.03        60\n",
      "          21       0.02      0.02      0.02        60\n",
      "          22       0.00      0.00      0.00        60\n",
      "          23       0.03      0.03      0.03        60\n",
      "          24       0.03      0.03      0.03        60\n",
      "          25       0.02      0.02      0.02        60\n",
      "          26       0.00      0.00      0.00        60\n",
      "          27       0.04      0.03      0.04        60\n",
      "          28       0.05      0.05      0.05        60\n",
      "          29       0.02      0.02      0.02        60\n",
      "          30       0.00      0.00      0.00        60\n",
      "          31       0.02      0.02      0.02        60\n",
      "          32       0.02      0.02      0.02        60\n",
      "          33       0.00      0.00      0.00        60\n",
      "          34       0.05      0.05      0.05        60\n",
      "          35       0.00      0.00      0.00        60\n",
      "          36       0.02      0.02      0.02        60\n",
      "          37       0.08      0.08      0.08        60\n",
      "          38       0.02      0.02      0.02        60\n",
      "          39       0.03      0.03      0.03        60\n",
      "          40       0.02      0.02      0.02        60\n",
      "          41       0.02      0.02      0.02        60\n",
      "          42       0.03      0.03      0.03        60\n",
      "          43       0.03      0.03      0.03        60\n",
      "          44       0.05      0.05      0.05        60\n",
      "          45       0.02      0.02      0.02        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.00      0.00      0.00        60\n",
      "          48       0.00      0.00      0.00        60\n",
      "          49       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 13s 143ms/step - loss: 0.6604 - accuracy: 0.9273\n",
      "Test accuracy: 0.9273333549499512\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Residual Block\n",
    "def residual_block(x, filters, kernel_size=3, strides=1, activation='relu'):\n",
    "    y = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation(activation)(y)\n",
    "\n",
    "    y = layers.Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "\n",
    "    if strides != 1 or x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, 1, strides=strides, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    out = layers.add([x, y])\n",
    "    out = layers.Activation(activation)(out)\n",
    "    return out\n",
    "\n",
    "# Model Architecture (ResNet)\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "x = layers.Conv2D(32, 3, strides=1, padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Stack of residual blocks\n",
    "x = residual_block(x, filters=64)\n",
    "x = residual_block(x, filters=128)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = residual_block(x, filters=128)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=100,  # Train for 100 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30531aba-5ace-4aab-8495-14e43cbf0b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 11s 27ms/step - loss: 3.7697 - accuracy: 0.0485 - val_loss: 3.3908 - val_accuracy: 0.1050\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 3.2283 - accuracy: 0.1280 - val_loss: 2.6680 - val_accuracy: 0.2303\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.6761 - accuracy: 0.2455 - val_loss: 1.7223 - val_accuracy: 0.4743\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.2422 - accuracy: 0.3500 - val_loss: 1.3203 - val_accuracy: 0.5887\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.9514 - accuracy: 0.4248 - val_loss: 1.1148 - val_accuracy: 0.6607\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.05      0.04        60\n",
      "           1       0.01      0.02      0.01        60\n",
      "           2       0.02      0.03      0.03        60\n",
      "           3       0.01      0.02      0.01        60\n",
      "           4       0.00      0.00      0.00        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.02      0.02      0.02        60\n",
      "           7       0.00      0.00      0.00        60\n",
      "           8       0.00      0.00      0.00        60\n",
      "           9       0.03      0.03      0.03        60\n",
      "          10       0.03      0.03      0.03        60\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.00      0.00      0.00        60\n",
      "          13       0.00      0.00      0.00        60\n",
      "          14       0.00      0.00      0.00        60\n",
      "          15       0.03      0.03      0.03        60\n",
      "          16       0.01      0.02      0.02        60\n",
      "          17       0.02      0.03      0.03        60\n",
      "          18       0.01      0.02      0.01        60\n",
      "          19       0.00      0.00      0.00        60\n",
      "          20       0.03      0.03      0.03        60\n",
      "          21       0.00      0.00      0.00        60\n",
      "          22       0.02      0.02      0.02        60\n",
      "          23       0.06      0.05      0.05        60\n",
      "          24       0.02      0.02      0.02        60\n",
      "          25       0.08      0.07      0.07        60\n",
      "          26       0.01      0.02      0.02        60\n",
      "          27       0.01      0.02      0.01        60\n",
      "          28       0.00      0.00      0.00        60\n",
      "          29       0.00      0.00      0.00        60\n",
      "          30       0.02      0.02      0.02        60\n",
      "          31       0.02      0.02      0.02        60\n",
      "          32       0.02      0.02      0.02        60\n",
      "          33       0.05      0.07      0.06        60\n",
      "          34       0.00      0.00      0.00        60\n",
      "          35       0.03      0.03      0.03        60\n",
      "          36       0.00      0.00      0.00        60\n",
      "          37       0.00      0.00      0.00        60\n",
      "          38       0.00      0.00      0.00        60\n",
      "          39       0.06      0.08      0.07        60\n",
      "          40       0.00      0.00      0.00        60\n",
      "          41       0.03      0.02      0.02        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.00      0.00      0.00        60\n",
      "          44       0.00      0.00      0.00        60\n",
      "          45       0.03      0.03      0.03        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.02      0.02      0.02        60\n",
      "          48       0.02      0.02      0.02        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 1.1148 - accuracy: 0.6607\n",
      "Test accuracy: 0.6606666445732117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (VGG)\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=5,  # Train for 5 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c648c4-6b20-4761-b008-4b213c52bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 11s 27ms/step - loss: 3.7092 - accuracy: 0.0507 - val_loss: 3.3097 - val_accuracy: 0.1123\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 3.1707 - accuracy: 0.1403 - val_loss: 2.4411 - val_accuracy: 0.3017\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.6242 - accuracy: 0.2524 - val_loss: 1.8154 - val_accuracy: 0.4587\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.2345 - accuracy: 0.3555 - val_loss: 1.4027 - val_accuracy: 0.5900\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.9611 - accuracy: 0.4278 - val_loss: 1.0815 - val_accuracy: 0.6650\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.7733 - accuracy: 0.4681 - val_loss: 0.9887 - val_accuracy: 0.6903\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.6418 - accuracy: 0.5117 - val_loss: 0.8828 - val_accuracy: 0.7277\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.5264 - accuracy: 0.5439 - val_loss: 0.7847 - val_accuracy: 0.7477\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.4272 - accuracy: 0.5670 - val_loss: 0.7719 - val_accuracy: 0.7450\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.3603 - accuracy: 0.5915 - val_loss: 0.6937 - val_accuracy: 0.7930\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.2931 - accuracy: 0.6070 - val_loss: 0.7189 - val_accuracy: 0.7787\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.2326 - accuracy: 0.6233 - val_loss: 0.6442 - val_accuracy: 0.7990\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.2017 - accuracy: 0.6302 - val_loss: 0.6658 - val_accuracy: 0.7903\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.1914 - accuracy: 0.6273 - val_loss: 0.6591 - val_accuracy: 0.7973\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.1399 - accuracy: 0.6482 - val_loss: 0.5739 - val_accuracy: 0.8247\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.1115 - accuracy: 0.6572 - val_loss: 0.5177 - val_accuracy: 0.8370\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.1013 - accuracy: 0.6627 - val_loss: 0.5305 - val_accuracy: 0.8330\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.0669 - accuracy: 0.6652 - val_loss: 0.5593 - val_accuracy: 0.8173\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.0418 - accuracy: 0.6772 - val_loss: 0.4856 - val_accuracy: 0.8453\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.0171 - accuracy: 0.6820 - val_loss: 0.5418 - val_accuracy: 0.8287\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.0216 - accuracy: 0.6822 - val_loss: 0.5467 - val_accuracy: 0.8220\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.9962 - accuracy: 0.6871 - val_loss: 0.4748 - val_accuracy: 0.8433\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.9793 - accuracy: 0.6944 - val_loss: 0.5001 - val_accuracy: 0.8357\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.9521 - accuracy: 0.6985 - val_loss: 0.4583 - val_accuracy: 0.8440\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.9484 - accuracy: 0.7022 - val_loss: 0.4816 - val_accuracy: 0.8473\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.9257 - accuracy: 0.7057 - val_loss: 0.4671 - val_accuracy: 0.8443\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.9248 - accuracy: 0.7035 - val_loss: 0.4821 - val_accuracy: 0.8517\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.9179 - accuracy: 0.7065 - val_loss: 0.4331 - val_accuracy: 0.8693\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.9071 - accuracy: 0.7149 - val_loss: 0.4936 - val_accuracy: 0.8480\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8731 - accuracy: 0.7268 - val_loss: 0.4483 - val_accuracy: 0.8607\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8834 - accuracy: 0.7188 - val_loss: 0.4622 - val_accuracy: 0.8537\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8586 - accuracy: 0.7281 - val_loss: 0.4322 - val_accuracy: 0.8610\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8633 - accuracy: 0.7234 - val_loss: 0.4274 - val_accuracy: 0.8593\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8832 - accuracy: 0.7194 - val_loss: 0.4055 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8686 - accuracy: 0.7258 - val_loss: 0.5005 - val_accuracy: 0.8287\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8485 - accuracy: 0.7287 - val_loss: 0.4238 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8320 - accuracy: 0.7358 - val_loss: 0.5835 - val_accuracy: 0.8190\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8336 - accuracy: 0.7350 - val_loss: 0.4357 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8330 - accuracy: 0.7322 - val_loss: 0.5020 - val_accuracy: 0.8387\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8114 - accuracy: 0.7370 - val_loss: 0.4911 - val_accuracy: 0.8443\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.8077 - accuracy: 0.7452 - val_loss: 0.4641 - val_accuracy: 0.8520\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7935 - accuracy: 0.7467 - val_loss: 0.4283 - val_accuracy: 0.8523\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7876 - accuracy: 0.7523 - val_loss: 0.4389 - val_accuracy: 0.8663\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7713 - accuracy: 0.7508 - val_loss: 0.5167 - val_accuracy: 0.8367\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7706 - accuracy: 0.7491 - val_loss: 0.4663 - val_accuracy: 0.8527\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7682 - accuracy: 0.7514 - val_loss: 0.4846 - val_accuracy: 0.8500\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7776 - accuracy: 0.7512 - val_loss: 0.4559 - val_accuracy: 0.8543\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7745 - accuracy: 0.7507 - val_loss: 0.4430 - val_accuracy: 0.8580\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7622 - accuracy: 0.7560 - val_loss: 0.4304 - val_accuracy: 0.8560\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7550 - accuracy: 0.7575 - val_loss: 0.4474 - val_accuracy: 0.8517\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7612 - accuracy: 0.7567 - val_loss: 0.4745 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7548 - accuracy: 0.7575 - val_loss: 0.4219 - val_accuracy: 0.8623\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7478 - accuracy: 0.7611 - val_loss: 0.4226 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7545 - accuracy: 0.7565 - val_loss: 0.5004 - val_accuracy: 0.8447\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7279 - accuracy: 0.7688 - val_loss: 0.5078 - val_accuracy: 0.8423\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7416 - accuracy: 0.7556 - val_loss: 0.4343 - val_accuracy: 0.8600\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7206 - accuracy: 0.7663 - val_loss: 0.4822 - val_accuracy: 0.8550\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7236 - accuracy: 0.7665 - val_loss: 0.4959 - val_accuracy: 0.8473\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7263 - accuracy: 0.7649 - val_loss: 0.4796 - val_accuracy: 0.8530\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7292 - accuracy: 0.7596 - val_loss: 0.5234 - val_accuracy: 0.8350\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7288 - accuracy: 0.7661 - val_loss: 0.5343 - val_accuracy: 0.8350\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7182 - accuracy: 0.7703 - val_loss: 0.4637 - val_accuracy: 0.8500\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7128 - accuracy: 0.7696 - val_loss: 0.5824 - val_accuracy: 0.8307\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7043 - accuracy: 0.7717 - val_loss: 0.5690 - val_accuracy: 0.8287\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7049 - accuracy: 0.7734 - val_loss: 0.4718 - val_accuracy: 0.8587\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.7014 - accuracy: 0.7725 - val_loss: 0.5346 - val_accuracy: 0.8453\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6986 - accuracy: 0.7804 - val_loss: 0.4812 - val_accuracy: 0.8457\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6934 - accuracy: 0.7819 - val_loss: 0.5152 - val_accuracy: 0.8427\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6736 - accuracy: 0.7812 - val_loss: 0.5765 - val_accuracy: 0.8233\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6850 - accuracy: 0.7800 - val_loss: 0.5170 - val_accuracy: 0.8407\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6759 - accuracy: 0.7824 - val_loss: 0.5224 - val_accuracy: 0.8440\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6819 - accuracy: 0.7808 - val_loss: 0.5443 - val_accuracy: 0.8250\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6857 - accuracy: 0.7768 - val_loss: 0.4411 - val_accuracy: 0.8657\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6899 - accuracy: 0.7818 - val_loss: 0.5663 - val_accuracy: 0.8403\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6932 - accuracy: 0.7778 - val_loss: 0.4525 - val_accuracy: 0.8610\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6670 - accuracy: 0.7853 - val_loss: 0.5612 - val_accuracy: 0.8260\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6608 - accuracy: 0.7822 - val_loss: 0.4516 - val_accuracy: 0.8627\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6678 - accuracy: 0.7810 - val_loss: 0.5947 - val_accuracy: 0.8250\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6742 - accuracy: 0.7835 - val_loss: 0.5623 - val_accuracy: 0.8310\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6652 - accuracy: 0.7889 - val_loss: 0.4836 - val_accuracy: 0.8480\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6600 - accuracy: 0.7882 - val_loss: 0.5301 - val_accuracy: 0.8350\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6789 - accuracy: 0.7803 - val_loss: 0.5228 - val_accuracy: 0.8373\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6522 - accuracy: 0.7883 - val_loss: 0.5673 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6629 - accuracy: 0.7884 - val_loss: 0.7212 - val_accuracy: 0.8030\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6566 - accuracy: 0.7849 - val_loss: 0.5687 - val_accuracy: 0.8257\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6542 - accuracy: 0.7864 - val_loss: 0.6035 - val_accuracy: 0.8217\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6504 - accuracy: 0.7880 - val_loss: 0.6206 - val_accuracy: 0.8170\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6381 - accuracy: 0.7958 - val_loss: 0.5132 - val_accuracy: 0.8390\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6456 - accuracy: 0.7880 - val_loss: 0.5384 - val_accuracy: 0.8317\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6354 - accuracy: 0.7938 - val_loss: 0.4985 - val_accuracy: 0.8417\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6234 - accuracy: 0.7983 - val_loss: 0.7336 - val_accuracy: 0.7967\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6340 - accuracy: 0.7958 - val_loss: 0.7299 - val_accuracy: 0.7920\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6390 - accuracy: 0.7951 - val_loss: 0.4549 - val_accuracy: 0.8590\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6323 - accuracy: 0.7918 - val_loss: 0.5088 - val_accuracy: 0.8497\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6371 - accuracy: 0.7951 - val_loss: 0.5695 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6307 - accuracy: 0.7972 - val_loss: 0.5055 - val_accuracy: 0.8543\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6393 - accuracy: 0.7940 - val_loss: 0.6414 - val_accuracy: 0.8020\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6360 - accuracy: 0.7955 - val_loss: 0.5013 - val_accuracy: 0.8430\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6267 - accuracy: 0.7977 - val_loss: 0.5911 - val_accuracy: 0.8233\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.6114 - accuracy: 0.7988 - val_loss: 0.6089 - val_accuracy: 0.8217\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03        60\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.06      0.05      0.06        60\n",
      "           3       0.02      0.02      0.02        60\n",
      "           4       0.05      0.05      0.05        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.02      0.02      0.02        60\n",
      "           7       0.04      0.05      0.04        60\n",
      "           8       0.05      0.03      0.04        60\n",
      "           9       0.00      0.00      0.00        60\n",
      "          10       0.00      0.00      0.00        60\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.06      0.05      0.06        60\n",
      "          13       0.01      0.02      0.02        60\n",
      "          14       0.02      0.02      0.02        60\n",
      "          15       0.06      0.07      0.07        60\n",
      "          16       0.03      0.03      0.03        60\n",
      "          17       0.02      0.02      0.02        60\n",
      "          18       0.00      0.00      0.00        60\n",
      "          19       0.03      0.03      0.03        60\n",
      "          20       0.02      0.02      0.02        60\n",
      "          21       0.09      0.05      0.06        60\n",
      "          22       0.00      0.00      0.00        60\n",
      "          23       0.00      0.00      0.00        60\n",
      "          24       0.04      0.05      0.04        60\n",
      "          25       0.00      0.00      0.00        60\n",
      "          26       0.05      0.05      0.05        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.05      0.05      0.05        60\n",
      "          29       0.03      0.02      0.02        60\n",
      "          30       0.02      0.03      0.02        60\n",
      "          31       0.02      0.02      0.02        60\n",
      "          32       0.02      0.02      0.02        60\n",
      "          33       0.02      0.03      0.03        60\n",
      "          34       0.01      0.02      0.01        60\n",
      "          35       0.01      0.02      0.02        60\n",
      "          36       0.01      0.02      0.01        60\n",
      "          37       0.02      0.02      0.02        60\n",
      "          38       0.03      0.03      0.03        60\n",
      "          39       0.00      0.00      0.00        60\n",
      "          40       0.05      0.05      0.05        60\n",
      "          41       0.02      0.02      0.02        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.02      0.02      0.02        60\n",
      "          44       0.00      0.00      0.00        60\n",
      "          45       0.02      0.02      0.02        60\n",
      "          46       0.00      0.00      0.00        60\n",
      "          47       0.05      0.03      0.04        60\n",
      "          48       0.03      0.03      0.03        60\n",
      "          49       0.03      0.03      0.03        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.6089 - accuracy: 0.8217\n",
      "Test accuracy: 0.8216666579246521\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model Architecture (VGG)\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=100,  # Train for 100 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea6fba6-f403-48f1-bf6a-2f48f5295ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 566s 2s/step - loss: 1.5718 - accuracy: 0.6027 - val_loss: 1.3899 - val_accuracy: 0.7783\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 560s 1s/step - loss: 0.4523 - accuracy: 0.8615 - val_loss: 0.5137 - val_accuracy: 0.8460\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 557s 1s/step - loss: 0.2292 - accuracy: 0.9272 - val_loss: 0.5137 - val_accuracy: 0.8523\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 557s 1s/step - loss: 0.1204 - accuracy: 0.9626 - val_loss: 0.5488 - val_accuracy: 0.8517\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 557s 1s/step - loss: 0.0952 - accuracy: 0.9680 - val_loss: 0.5722 - val_accuracy: 0.8670\n",
      "94/94 [==============================] - 34s 360ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.02      0.02        60\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.02      0.02      0.02        60\n",
      "           3       0.02      0.02      0.02        60\n",
      "           4       0.03      0.03      0.03        60\n",
      "           5       0.04      0.03      0.03        60\n",
      "           6       0.04      0.03      0.04        60\n",
      "           7       0.00      0.00      0.00        60\n",
      "           8       0.02      0.02      0.02        60\n",
      "           9       0.03      0.03      0.03        60\n",
      "          10       0.00      0.00      0.00        60\n",
      "          11       0.02      0.02      0.02        60\n",
      "          12       0.02      0.03      0.03        60\n",
      "          13       0.03      0.05      0.04        60\n",
      "          14       0.00      0.00      0.00        60\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.02      0.02      0.02        60\n",
      "          17       0.00      0.00      0.00        60\n",
      "          18       0.02      0.02      0.02        60\n",
      "          19       0.01      0.02      0.01        60\n",
      "          20       0.02      0.02      0.02        60\n",
      "          21       0.02      0.02      0.02        60\n",
      "          22       0.01      0.02      0.02        60\n",
      "          23       0.01      0.02      0.02        60\n",
      "          24       0.00      0.00      0.00        60\n",
      "          25       0.04      0.03      0.04        60\n",
      "          26       0.00      0.00      0.00        60\n",
      "          27       0.00      0.00      0.00        60\n",
      "          28       0.02      0.02      0.02        60\n",
      "          29       0.02      0.02      0.02        60\n",
      "          30       0.02      0.02      0.02        60\n",
      "          31       0.03      0.02      0.02        60\n",
      "          32       0.02      0.02      0.02        60\n",
      "          33       0.02      0.02      0.02        60\n",
      "          34       0.02      0.02      0.02        60\n",
      "          35       0.04      0.07      0.05        60\n",
      "          36       0.04      0.03      0.04        60\n",
      "          37       0.04      0.03      0.04        60\n",
      "          38       0.04      0.03      0.04        60\n",
      "          39       0.00      0.00      0.00        60\n",
      "          40       0.00      0.00      0.00        60\n",
      "          41       0.02      0.02      0.02        60\n",
      "          42       0.00      0.00      0.00        60\n",
      "          43       0.02      0.02      0.02        60\n",
      "          44       0.02      0.02      0.02        60\n",
      "          45       0.05      0.05      0.05        60\n",
      "          46       0.05      0.05      0.05        60\n",
      "          47       0.00      0.00      0.00        60\n",
      "          48       0.00      0.00      0.00        60\n",
      "          49       0.02      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.02      3000\n",
      "   macro avg       0.02      0.02      0.02      3000\n",
      "weighted avg       0.02      0.02      0.02      3000\n",
      "\n",
      "94/94 [==============================] - 34s 360ms/step - loss: 0.5722 - accuracy: 0.8670\n",
      "Test accuracy: 0.8669999837875366\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Inception Module\n",
    "def inception_module(x, filters):\n",
    "    branch1x1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    branch3x3 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch3x3 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(branch3x3)\n",
    "\n",
    "    branch5x5 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch5x5 = layers.Conv2D(filters, (5, 5), padding='same', activation='relu')(branch5x5)\n",
    "\n",
    "    branch_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(branch_pool)\n",
    "\n",
    "    output = layers.concatenate([branch1x1, branch3x3, branch5x5, branch_pool], axis=-1)\n",
    "    return output\n",
    "\n",
    "# Model Architecture (Inception)\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "x = layers.Conv2D(32, 3, strides=1, padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Stack of inception modules\n",
    "x = inception_module(x, filters=64)\n",
    "x = inception_module(x, filters=128)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = inception_module(x, filters=128)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=5,  # Train for 5 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e001df-bd79-49a7-ae8e-29e34b575213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\habib\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "375/375 [==============================] - 585s 2s/step - loss: 1.7954 - accuracy: 0.5611 - val_loss: 1.5193 - val_accuracy: 0.6913\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 582s 2s/step - loss: 0.5669 - accuracy: 0.8275 - val_loss: 0.6149 - val_accuracy: 0.8190\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 584s 2s/step - loss: 0.3110 - accuracy: 0.8980 - val_loss: 0.5561 - val_accuracy: 0.8533\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 585s 2s/step - loss: 0.1842 - accuracy: 0.9413 - val_loss: 0.5522 - val_accuracy: 0.8593\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 588s 2s/step - loss: 0.1233 - accuracy: 0.9577 - val_loss: 0.5911 - val_accuracy: 0.8603\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 572s 2s/step - loss: 0.1004 - accuracy: 0.9651 - val_loss: 0.5484 - val_accuracy: 0.8627\n",
      "Epoch 7/100\n",
      "326/375 [=========================>....] - ETA: 1:07 - loss: 0.0785 - accuracy: 0.9746"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Train'\n",
    "test_dir = r'D:\\thesis\\code\\bangla_Handwritten_data\\Test'\n",
    "\n",
    "# Count the number of classes based on the number of subfolders in the training directory\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Other preprocessing techniques like rotation, zoom, etc. can be added here\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(50, 50),  # Resizing to 50x50 dimensions\n",
    "    color_mode='grayscale',  # Convert images to grayscale\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Inception Module\n",
    "def inception_module(x, filters):\n",
    "    branch1x1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    branch3x3 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch3x3 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(branch3x3)\n",
    "\n",
    "    branch5x5 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch5x5 = layers.Conv2D(filters, (5, 5), padding='same', activation='relu')(branch5x5)\n",
    "\n",
    "    branch_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(branch_pool)\n",
    "\n",
    "    output = layers.concatenate([branch1x1, branch3x3, branch5x5, branch_pool], axis=-1)\n",
    "    return output\n",
    "\n",
    "# Model Architecture (Inception)\n",
    "inputs = layers.Input(shape=(50, 50, 1))\n",
    "x = layers.Conv2D(32, 3, strides=1, padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Stack of inception modules\n",
    "x = inception_module(x, filters=64)\n",
    "x = inception_module(x, filters=128)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = inception_module(x, filters=128)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=100,  # Train for 100 epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_labels)\n",
    "print(report)\n",
    "\n",
    "# Additional Evaluation (Accuracy)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a848146-f843-47e4-8ccf-667ee7ace595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
